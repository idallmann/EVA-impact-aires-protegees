# (PART\*) Impact analysis {.unnumbered}

# Matching

In this R Markdown are performed the different steps to obtain a matched dataset, i.e a dataset with control and treated observational units to compute the treatment effect. The treatment here is to be under protected area status, and we look at the impact on deforestation.

The steps are the following

1.  Pre-processing : in a loop for each country

    1.  Create a grid of the country

    2.  Import geospatial data on PAs from the WDPA dataset, and assign each observation unit/pixel to a group : PA funded by the AFD (treated), PA non-funded by the AFD, buffer (closed to but not a PA), other (so potential control).

    3.  Compute the covariates and outcome of interest in all pixels thanks to the mapme.biodiversity package

    4.  Build the matching data frame : each pixel is assigned to a group and has covariates and outcome values.

2.  Post-processing : in a loop for each country

    1.  Load the matching dataframe of the given country

    2.  Perform the matching

    3.  Plot covariate balance and density plots to ensure relevant matching

    4.  Panelize the dataframe

    5.  Perform regressions

## Initial settings

```{r setup, include=FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) 
```

Install and import the relevant packages

```{r eval=, message=FALSE, warning=FALSE}
#Install some libraries
install.packages(c("tictoc", "geodata", "wdpar", "exactextractr", "MatchIt", "fixest", "cobalt", "future", "progressr", "mapme.biodiversity", "future.callr", "janitor", "geomtextpath", "rstac"))
#remotes::install_github("mapme-initiative/mapme.biodiversity", upgrade="always")
#remotes::install_github("prioritizr/wdpar", upgrade="always")

#Install the web driver to download wdpa data directly
webdriver::install_phantomjs()  

# Load Libraries
library(dplyr)
library(janitor)
library(tictoc) #For timing
library(xtable)
library(tidyr)
library(stringr)
library(ggplot2) # For plotting
library(geomtextpath) #For annoted vertical lines in ggplot
library(RColorBrewer)
library(ggrepel)
library(sf) # For handling vector data
library(terra) # For handling raster data
library(raster) # For handling raster data
library(rgeos)
library(geodata) # For getting country files
library(wdpar) # For getting protected areas
library(exactextractr) # For zonal statistics
library(mapme.biodiversity)
library(aws.s3)
library(MatchIt) #For matching
library(fixest) #For estimating the models
library(cobalt) #To visualize density plots and covariate balance from MatchIt outcomes
library(future) #For parallel computing in mapme.biodiversity
library(future.callr)
library(progressr) # To display progress bar   
library(rstac) #To downlad NASA SRTM data
```

Set the credentials to access to the storage. This is useful to get rid of the time restriction due to token expiration (24h). In the SSPCloud, it is necessary to create a R session without any temporary access configuration to s3 server, then to run the following code.

```{r, eval = F}
# Sys.setenv("AWS_ACCESS_KEY_ID" = "Q4ssrrU8UxugYW73sIoT",
#            "AWS_SECRET_ACCESS_KEY" = "2WwG5OP7EyEWML5XmcQ8x0a0XWbZ1wvzoFWGNyT5",
#            "AWS_DEFAULT_REGION" = "us-east-1",
#            "AWS_S3_ENDPOINT"= "minio.lab.sspcloud.fr")
# bucketlist(region="")
```

```{r message=FALSE, warning=FALSE, eval = FALSE}
#Import functions
source("scripts/functions/02_fns_matching.R")      
```

```{r, eval = FALSE}
# Define the path to a temporary, working directory for pre- and post-processing steps.
# Define a directory where outputs are stored in SSPCloud.
tmp_pre = paste(tempdir(), "matching_pre", sep = "/")
tmp_post = paste(tempdir(), "matching_post", sep = "/")
save_dir = paste("impact_analysis/matching", Sys.Date(), sep = "/")
# save_dir = paste("impact_analysis/matching", "2023-08-29", sep = "/")

#####
###Pre-processing
#####

#(Down)load WDPA database   
##Download
# wdpa_wld_raw = wdpa_fetch(x = "global", wait = TRUE, download_dir = tmp_pre, page_wait = 2, verbose = TRUE)
# s3write_using(wdpa_wld_raw,
#               sf::st_write,
#               delete_dsn = TRUE,
#               object = paste0("data_raw/wdpa/wdpa_shp_global_raw.gpkg"),
#               bucket = "projet-afd-eva-ap",   
#               opts = list("region" = ""))

##Load
wdpa_wld_raw = s3read_using(
              sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

# Specify buffer width in meter
buffer_m = 10000
# Specify the grid cell size in meter
gridSize = 1e3

#Load data
##AFD
# data_pa =
#   #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
#   aws.s3::s3read_using(
#   FUN = data.table::fread,
#   encoding = "UTF-8",
#   object = "data_tidy/BDD_PA_AFD_ie.csv",
#   bucket = "projet-afd-eva-ap",
#   opts = list("region" = "")) %>%
#   #Sangha trinational (555547988) created in 2012 actually gathers three former PAs
#   #in CAF (31458), CMR (1245) and COG (72332) implemented in
#   #1990, 2001 and 1993 respectively.
#   # Evaluating the trinational PA is not relevant here : our method relies on pre-treatment obervsations (for matching and DiD) and the outcome is likely to be affected by the initial PAs. On the other hand, evaluating the three earlier PAs might be irrelevant for us : are they funded by the AFD ?? In a first approach, the trinational is removed.
#   filter(is.na(wdpaid) == TRUE | wdpaid != 555547988)
##FAPBM
# data_pa =
#   #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
#   aws.s3::s3read_using(
#   FUN = data.table::fread,
#   encoding = "UTF-8",
#   object = "data_tidy/BDD_PA_FAPBM.csv",
#   bucket = "projet-afd-eva-ap",
#   opts = list("region" = ""))
##MDG
data_pa =
  #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_PA_MDG.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

#List of countries in the sample
# list_iso_africa = unique(data_pa[data_pa$region == "Africa", iso3])
# list_iso = list_iso_africa[c(1:13, 15:22, 24)] #All ISO except GAB and ZZ
#list_iso = list_iso_africa[15:24]
# list_iso = list_iso_africa[16:24]

list_iso = "MDG"
      
#Specify the period of study to create the mapme.bidiversity portfolio
## Start year
yr_first = 2000
## End year
yr_last = 2021

#Minimum treatment year
#At least two pre-treatment periods of forest cover are needed to compute average pre-treatment deforestation
yr_min = yr_first+2

#####
###Post-processing
#####

# Define Column Names of Covariates
colname.travelTime = "minutes_median_5k_110mio"
colname.clayContent = "clay_0_5cm_mean"
colname.elevation = "elevation_mean"
colname.tri = "tri_mean"
colname.fcIni = "treecover_2000"
colname.biome = "biomes"


# Prefix of columns for forest cover
colfc.prefix = "treecover"
# Separation between prefix and year
colfc.bind = "_"
# Prefix of columns for forest loss
colfl.prefix = "treeloss"
#Prefix of columns for average forest loss pre-funding
colname.flAvg = "avgLoss_pre_fund"
       
```

## Matching process

For pre- and post-processing steps, the different functions are called in a loop (one iteration per country).

### Pre-processing

```{r message=FALSE, warning=FALSE, eval = FALSE}
#For each country in the list, the different steps of the pre-processing are performed
count = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_pre = tic() #Start timer

#Create a log to track progress
log = fn_pre_log(list_iso,
                 name = paste0("log-", Sys.Date(), "-MDG-all-wdpa.txt"),
                 notes = "An analysis of all PAs in MDG reported by the WDPA. The idea is to compare the effectiveness of PAs funded by the FAPBM relative to other PAs in Madagascar. Note that the computations are performed on a session without time restrictions in the access to the S3 server.")

for (i in list_iso)            
{
  #Update counter and display progress
  count = count+1
  print(paste0(i, " : country ", count, "/", max_i))
  
  #Append the log to track progress of the process on country i
  cat(paste("#####\nCOUNTRY :", i, "\n#####\n\n"), file = log, append = TRUE)
     
  
  #Generate observation units
  print("--Generating observation units")
  output_grid = fn_pre_grid(iso = i, 
                            yr_min = yr_min,
                            path_tmp = tmp_pre, 
                            data_pa = data_pa,
                            gridSize = gridSize,
                            log = log,
                            save_dir = save_dir)
  if(output_grid$is_ok == FALSE) {next}
  
  #Load the outputs 
  utm_code = output_grid$utm_code
  gadm_prj = output_grid$ctry_shp_prj
  grid = output_grid$grid
  
  #Determining Group IDs and WDPA IDs for all observation units
  print("--Determining Group IDs and WDPA IDs")
  output_group = fn_pre_group(iso = i, wdpa_raw = wdpa_wld_raw,
                              status = c("Proposed", "Designated", "Inscribed", "Established"),
                            yr_min = yr_min,
                            path_tmp = tmp_pre, utm_code = utm_code,
                            buffer_m = buffer_m, data_pa = data_pa,
                            gadm_prj = gadm_prj, grid = grid, 
                            gridSize = gridSize,
                            log = log,
                            save_dir = save_dir)
  if(output_group$is_ok == FALSE) {next} else grid_param = output_group$grid.param

  #Calculating outcome and other covariates for all observation units
  print("--Calculating outcome and other covariates")
  output_mf = 
    fn_pre_mf_parallel(grid.param = grid_param, path_tmp = tmp_pre, iso = i,
          name_output = paste0("matching_frame_spling", n_sampling),
          ext_output = ".gpkg",
          yr_first = yr_first, yr_last = yr_last,  
          log = log,
          save_dir = save_dir)  
  if(output_mf$is_ok == FALSE) {next}                                            
  
  #Remove files in the session memory
  tmp_files = list.files(tmp_pre, include.dirs = T, full.names = T, recursive = T)
  file.remove(tmp_files)
                                  
}                            
  
  #End timer for pre-processing
  toc_pre = toc()
  
  #Append the log
  cat(paste("END OF PRE-PROCESSING :", toc_pre$callback_msg, "\n\n"), 
      file = log, append = TRUE)

           
 
```

### Post-processing

```{r message=FALSE, warning=FALSE, eval = FALSE}
#For each country in the list, the different steps of the post-processing are performed
count_i = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_post = tic() #start timer

#Append the log
cat(paste("##########\nPOST-PROCESSING\n##########\n\n"), 
    file = log, append = TRUE)
  
for (i in list_iso)
{
  #Update counter and show progress
  count_i = count_i+1
  print(paste0(i, " : country ", count_i, "/", max_i))
  
  #Append the log to track progress of the process on country i
  cat(paste("#####\nCOUNTRY :", i, "\n"), file = log, append = TRUE)
  
  #Load the matching frame
  print("--Loading the matching frame")
  output_load = fn_post_load_mf(iso = i, 
                           yr_min = yr_min,
                           name_input = paste0("matching_frame_spling", n_sampling),
                           ext_input = ".gpkg",
                           log = log,
                           save_dir = save_dir)
  if(output_load$is_ok == FALSE) {next} else mf_ini = output_load$mf
  
  list_pa = unique(mf_ini[mf_ini$wdpaid != 0, ]$wdpaid)
  
    #Append the log : list of PAs analyzed in the matching frame
  cat(paste("LIST OF WDPAIDs :", paste(list_pa, collapse = ", "), "\n#####\n\n"), 
      file = log, append = TRUE)
    
  #Initialization
  ##Counter
  count_j = 0
  max_j = length(list_pa)
  ##List of control and treatment pixels matched
  df_pix_matched = data.frame()
  
  #Loop over the different PAs
  for (j in list_pa)
  {
    #Update counter and show progress
    count_j = count_j+1
    print(paste0("WDPAID : ", j, " : ", count_j, "/", max_j))
    
    #Append the log to track progress of the process on PA j
    cat(paste("###\nWDPAID :", j, "\n###\n\n"), file = log, append = TRUE)
  
    mf_ini_j = mf_ini %>%
      filter(group == 1 | (group == 2 & wdpaid == j))
    
    #Add average pre-loss
    print("--Add covariate : average tree loss pre-funding")
    output_avgLoss = fn_post_avgLoss_prefund(mf = mf_ini_j, 
                                             colfl.prefix = colfl.prefix,
                                             log = log)
    if(output_avgLoss$is_ok == FALSE) {next} else mf_j = output_avgLoss$mf
    
    #Run Coarsened Exact Matching
    print("--Run CEM")
    output_cem = fn_post_match_auto(mf = mf_j, iso = i, 
                                   dummy_int = FALSE,
                                     th_mean = 0.1, 
                                     th_var_min = 0.5, th_var_max = 2,
                                   colname.travelTime = colname.travelTime, 
                                   colname.clayContent = colname.clayContent, 
                                   colname.elevation = colname.elevation,
                                   colname.tri = colname.tri, 
                                   colname.fcIni = colname.fcIni, 
                                   colname.flAvg = colname.flAvg,
                                   colname.biome = colname.biome,
                                   log = log)
    if(output_cem$is_ok == FALSE) {next} else out_cem_j = output_cem$out.cem
    
    #Plots : covariates
    print("--Some plots : covariates")
    print("----Covariate balance")
    output_covbal = fn_post_covbal(out.cem = out_cem_j,
                   mf = mf_j,
                   colname.travelTime = colname.travelTime, 
                   colname.clayContent = colname.clayContent,
                   colname.fcIni = colname.fcIni, 
                   colname.flAvg = colname.flAvg,
                   colname.tri = colname.tri,
                   colname.elevation = colname.elevation,
                   colname.biome = colname.biome,
                   iso = i,
                   path_tmp = tmp_post,
                   wdpaid = j,
                   log = log,
                   save_dir = save_dir)
  if(output_covbal$is_ok == FALSE) {next}
    
    print("----Density plots")
    output_density = fn_post_plot_density(out.cem = out_cem_j, 
                                         mf = mf_j,
                                      colname.travelTime = colname.travelTime, 
                                       colname.clayContent = colname.clayContent,
                                       colname.fcIni = colname.fcIni, 
                                       colname.flAvg = colname.flAvg,
                                    colname.tri = colname.tri,
                                   colname.elevation = colname.elevation,
                                      iso = i,
                                      path_tmp = tmp_post,
                                      wdpaid = j,
                                   log = log,
                                   save_dir = save_dir)
     if(output_density$is_ok == FALSE) {next}
    
    #Panelize dataframes
    print("----Panelize (Un-)Matched Dataframe")
    output_panel = fn_post_panel(out.cem = out_cem_j, 
                                  mf = mf_j, 
                                  colfc.prefix = colfc.prefix, 
                                  colfc.bind = colfc.bind,
                                  ext_output = ".csv", 
                                  iso = i,
                                  wdpaid = j,
                                  log = log,
                                 save_dir = save_dir)
     if(output_panel$is_ok == FALSE) {next}
    
    matched.wide.j = output_panel$matched.wide
    unmatched.wide.j = output_panel$unmatched.wide
    matched.long.j = output_panel$matched.long
    unmatched.long.j = output_panel$unmatched.long 
    
    #Extract matched units and plot them on a grid
    print("----Extract matched units and plot them on a grid")
    ##Extract ID of treated and control pixels
    df_pix_matched_j = matched.wide.j %>%
      st_drop_geometry() %>%
      as.data.frame() %>%
      dplyr::select(c(group, assetid)) %>%
      rename("group_matched" = "group") 
    df_pix_matched = rbind(df_pix_matched, df_pix_matched_j)
    ##Plot the grid with matched control and treated for the PA
    output_grid = fn_post_plot_grid(iso = i, wdpaid = j,
                      is_pa = TRUE,
                      df_pix_matched = df_pix_matched_j,
                      path_tmp = tmp_post,
                      log = log,
                      save_dir = save_dir)
     if(output_grid$is_ok == FALSE) {next}
  
    
  
    #Plots : trend
    print("----Plots again : trend")
    output_trend = fn_post_plot_trend(matched.long = matched.long.j, 
                       unmatched.long = unmatched.long.j, 
                       mf = mf_j,
                       data_pa = data_pa,
                       iso = i,
                       wdpaid = j,
                       log = log,
                       save_dir = save_dir)
    if(output_trend$is_ok == FALSE) {next}
  }
    
  # Plot the grid with matched control and treated for the country 
  output_grid = fn_post_plot_grid(iso = i, wdpaid = j,
                    is_pa = FALSE,
                    df_pix_matched = df_pix_matched,
                    path_tmp = tmp_post,
                    log = log,
                    save_dir = save_dir)
   if(output_grid$is_ok == FALSE) {next}
  
}       

#End post-processing timer
toc_post = toc()

#Append the log and save it
cat(paste("END OF POST-PROCESSING :", toc_post$callback_msg, "\n\n"),
    file = log, append = TRUE)
aws.s3::put_object(file = log,
                   bucket = paste("projet-afd-eva-ap", save_dir, sep = "/"),
                   region = "",
                   show_progress = FALSE)
                 
                               
#Notes
## Automate the definition of cutoffs for CEM
### Coder 5.5.3 de Iacus et al. 2012 ? Permet de savoir le gain de matched units pour une modification des seuils d'une variable
## Allow to enter a list of any covariates to perform the matching
## Function to plot Fig. 3 in Iacus et al. 2012
## On veut ATE ou ATT ?? Je dirai ATT car on ne veut pas estimer l'effet de mettre une AP, mais l'effet des AP financés par l'AFD 
                                                                           
                               
```
