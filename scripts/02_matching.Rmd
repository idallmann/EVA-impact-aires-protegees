
# (PART\*) Impact analysis {.unnumbered}

# Matching

In this R Markdown are performed the different steps to obtain a matched dataset, i.e a dataset with control and treated observational units to eventually compute the treatment effect. The treatment here is to be under protected area status, and we look at the impact on deforestation.

The steps are the following.

1.  Pre-processing : in a loop for each country,

    1.  create a gridding of the country;

    2.  import geospatial data on protected areas (PAs) from the World Dataset on Protected Areas (WDPA) and assign each observation unit/pixel to a group : PA of interest and analyzed (treated), PA of interest but not analyzed, PA not of interest, buffer (pixel closed to but not in a PA), other (so potential control). A PA of interest can be a PA known to be supported by the Agence Française de Développement (AFD) for instance. Some PAs are of interest but cannot be analyzed due to the design of the methodology (e.g marine protected areas when the focus is on deforestation);

    3.  compute the covariates and outcome of interest in all pixels thanks to the mapme.biodiversity package;

    4.  build the matching data frame : each pixel is assigned to a group and has covariates and outcome values.

2.  Post-processing : in each country,

    1.  Load the matching dataframe obtained at the end of pre-processing for a given country, and extract the list of protected areas to process.

    2.  For each protected area,

        1.  perform the matching;

        2.  plot covariate balance and density plots to assess the quality of the match;

        3.  panelize the dataframe;

        4.  plot the evolution of forest cover in treated and control areas, before and after matching;

        5.  map the matched treated and control units.

    3.  Map all matched treated and control units in the country.

The methodology is not extensively described here to keep the documentation concise. The interested reader can refer to the working paper for more details.

## Initial settings

Configuring the Rmarkdown

```{r setup, include=FALSE, eval = FALSE}

knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

```

Downloading and installing the relevant packages

```{r eval= F, message=FALSE, warning=FALSE}
#Install some libraries
## CRAN version
install.packages(c("tictoc", "geodata", "wdpar", "exactextractr", "MatchIt", "fixest", "cobalt", "future", "progressr", "future.callr", "janitor", "geomtextpath", "rstac","ggrepel","landscapemetrics"))
## Github version (can be relevant if some features have not made it to CRAN version yet)
remotes::install_github("mapme-initiative/mapme.biodiversity", upgrade="always")
#remotes::install_github("prioritizr/wdpar", upgrade="always")

#Install the web driver to download wdpa data directly
#webdriver::install_phantomjs()  

# Load Libraries
library(dplyr)
library(janitor) #Functions to automate name cleaning
library(tictoc) #For timing
library(xtable) #Export dataframes as tables
library(tidyr)
library(stringr) #String specific functions
library(ggplot2) # For plotting
library(geomtextpath) #For annoted vertical lines in ggplot
library(RColorBrewer) #Improved color palettes for plot legends
library("ggrepel") #Refine labelling of some figures
library(sf) # For handling vector data
library(terra) # For handling raster data
library(raster) # For handling raster data
library(geodata) # For getting country files
library(wdpar) # For getting protected areas
library(exactextractr) # For zonal statistics
library(mapme.biodiversity) #Download geospatial data and compute specific indicators
library(rstac) #To downlad NASA SRTM data
library(aws.s3) #Access to storage
library(MatchIt) #For matching
library(fixest) #For estimating the models
library(cobalt) #To visualize density plots and covariate balance from MatchIt outcomes
library(future) #For parallel computing in mapme.biodiversity
library(future.callr)  #For parallel computing in mapme.biodiversity
library(progressr) # To display progress bar   
library(data.table)
library(landscapemetrics)
```


```{r eval= F, message=FALSE, warning=FALSE}
# Add this, to download correctly travel data 

Sys.setenv(
  "VSI_CACHE" = "TRUE",
  "CPL_VSIL_CURL_CHUNK_SIZE" = "10485760",
  "GDAL_HTTP_MAX_RETRY" = "5",
  "GDAL_HTTP_RETRY_DELAY" = "15"
)

```





Load the R functions called in the data processing

```{r message=FALSE, warning=FALSE, eval = FALSE}
#Import functions
source("scripts/functions/02_fns_matching_GIE_makira.R")      
```

## Datasets and critical parameters

```{r, eval = FALSE}
# Define working directories
## Define the path to a temporary, working directory processing steps.

tmp_pre = paste(tempdir(), "matching_pre", sep = "/")
tmp_post = paste(tempdir(), "matching_post", sep = "/")
## Define a directory where outputs are loaded from/stored in SSPCloud.
save_dir = paste("impact_analysis/matching", Sys.Date(), sep = "/") #Today's date
load_dir = paste("impact_analysis/matching", Sys.Date(), sep = "/")
save_dir = paste("impact_analysis/matching", "nearest_maha_replace", sep = "/") #A specific date
 load_dir = paste("impact_analysis/matching", "2024-08-13", sep = "/")# date où la bdd de matching de Makira a été créée

# Load datasets
## WDPA database : just has to be done once to download last version of the WDPA database  
## Download and save
# wdpa_wld_raw = wdpa_fetch(x = "global", wait = TRUE, download_dir = tmp_pre, page_wait = 2, verbose = TRUE)
# s3write_using(wdpa_wld_raw,
#               sf::st_write,
#               delete_dsn = TRUE,
#               object = paste0("data_raw/wdpa/wdpa_shp_global_raw.gpkg"),
#               bucket = "projet-afd-eva-ap",   
#               opts = list("region" = ""))

##Load
## /!\ Do not forget to specify SSP CLoud credentials (_00_acess_minio_credentials.Rmd)
wdpa_wld_raw = s3read_using(
              sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

## Dataset specific to the PAs portfolio to analyze. Only one is selected depending on the analysis one wants to perform. 
### PAs supported by the AFD
data_pa =
  #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_PA_AFD_ie.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) %>%
  #Sangha trinational (555547988) created in 2012 actually gathers three former PAs
  #in CAF (31458), CMR (1245) and COG (72332) implemented in
  #1990, 2001 and 1993 respectively.
  # Evaluating the trinational PA is not relevant here : our method relies on pre-treatment obervsations (for matching and DiD) and the outcome is likely to be affected by the initial PAs. On the other hand, evaluating the three earlier PAs might be irrelevant for us : are they funded by the AFD ?? In a first approach, the trinational is removed.
  filter(is.na(wdpaid) == TRUE | wdpaid != 555547988)

## PAs supported by the FAPBM
# data_pa =
#   #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
#   aws.s3::s3read_using(
#   FUN = data.table::fread,
#   encoding = "UTF-8",
#   object = "data_tidy/BDD_PA_FAPBM.csv",
#   bucket = "projet-afd-eva-ap",
#   opts = list("region" = ""))

## All PAs in Madagascar
# data_pa =
#   aws.s3::s3read_using(
#   FUN = data.table::fread,
#   encoding = "UTF-8",
#   object = "data_tidy/BDD_PA_MDG.csv",
#   bucket = "projet-afd-eva-ap",
#   opts = list("region" = ""))

# All PAs in Africa
data_pa =
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_PA_africa.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))


# Specify buffer width in meter
buffer_m = 10000
# Specify the grid cell size in meter
gridSize = 1000

#Specify the period of study to create the mapme.bidiversity portfolio
## Start year
yr_first = 2000
## End year
yr_last = 2021

#Minimum treatment year
#At least two pre-treatment periods of forest cover are needed to compute average pre-treatment deforestation, used as a matching variable.
yr_min = yr_first+2

# Define column names of matching covariates
colname.travelTime = "minutes_mean_5k_110mio"
colname.clayContent = "clay_0_5cm_mean"
colname.elevation = "elevation_mean"
colname.tri = "tri_mean" #Terrain Ruggedness Index
colname.fcAvg = "avgCover_pre_treat"  #Forest cover pre-treatment
colname.flAvg = "avgLoss_pre_treat" #Forest loss pre-treatment
#colname.biome = "biomes"
list_cov = paste(colname.travelTime, colname.clayContent, colname.elevation, colname.tri, colname.fcAvg, colname.flAvg
                 #,colname.biome
                 , sep = ";")


#Matching 
## Parameters
match_method = "cem"
cutoff_method = "sturges"
k2k_method = "mahalanobis"
is_k2k = FALSE
## Criteria to assess matching quality
### Standardized absolte mean difference : threshold
th_mean = 0.25 #Used in conservation science, see Desbureaux 2021 for instance
### Variance ratio : thresholds
th_var_min = 0.5
th_var_max = 2
       
# The list of countries (ISO3 codes) to analyze. This can be define manually or from the the dataset loaded.
##List of African countries in the sample that have at least one PA supported by the AFD we can analyse
data_pa_ie_africa_focus = data_pa %>%
  dplyr::filter(region == "Africa" & is.na(wdpaid) == FALSE & area_km2 >=1 & marine %in% c(0,1) & status_yr >= yr_min & focus == T)
list_iso = unique(data_pa_ie_africa_focus$iso3)

# ## Manual definition
# list_iso = c("COM", "GNB")
list_iso=c("KEN")
```

## Matching process

The following code is divided into pre- and post-processing steps (see above). At pre-processing stage, computations are done country-by-country. At post-proccessing stage, computations are done country-by-country and protected areas by protected areas. To facilitate the reading, each step consists in a call of a function define in an other R script.

During the process, a text file (so-called log) is edited to keep track of the differents steps. Then after each critical step, the code checks whether an error occured by interrogating the variable is_ok (defined in the function corresponding to the step). If the step is ok (is_ok = TRUE) then the processing continues. Otherwise, the code goes to the next iteration (next country for pre-processing, next protected area for post-processing). This is useful in a multi-country, multi-PA analysis, to avoid the code to stop when an error occurs. Instead, the code continue and the analyst can see in the log whether there have been errors during the processing, where it happened and whether he or she needs to launch the analysis again for a specific country/PA. Generally speaking, this log is useful to remember what has been analyzed and assess everything was fine after the processing (warnings, processing of all the countries and PAs, etc.).

For more details about the each step, please refer to the definition of the functions.

### PRE-PROCESSING 


 The analysis is designed to analyze a portfolio of PA in different countries, using loop over countries and over PA. To better understand a function, or identify and debug an error, a good practice is to enter the loops using a single country or PA. Thus, it is possible to run the analysis step by step, and even enter into the functions to understand what is done « behind the doors ». For instance in « 02_matching.Rmd), set value i = « COM » in the first loop and j = 313046 to peform the analysis step by step for PA with WDPA ID 313046 in Comoros.

```{r message=FALSE, warning=FALSE, eval = FALSE}
#For each country in the list, the different steps of the pre-processing are performed, and the process duration computed
count = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_pre = tic() #Start timer

#Create a log to track progress of the analysis
log = fn_pre_log(list_iso,
                 buffer = buffer_m,
                 gridSize = gridSize,
                 yr_first = yr_first,
                 yr_last = yr_last,
                 yr_min = yr_min,
                 list_cov = list_cov,
                 name = paste0("log-", Sys.Date(), "-TEST.txt"),
                 notes = "Specific notes or remarks.")

# Perform pre-processing steps country-by-country
for (i in list_iso)            
{
  #Update counter and display progress
  count = count+1
  print(paste0(i, " : country ", count, "/", max_i))
  
  #Append the log to track progress of the process on country i
  cat(paste("#####\nCOUNTRY :", i, "\n#####\n\n"), file = log, append = TRUE)
     
  #Generate observation units
  print("--Generating observation units")
  output_grid = fn_pre_grid(iso = i, 
                            yr_min = yr_min,
                            path_tmp = tmp_pre, 
                            data_pa = data_pa,
                            gridSize = gridSize,
                            log = log,
                            save_dir = save_dir)
  if(output_grid$is_ok == FALSE) {next}  
  
  #Load the outputs 
  utm_code = output_grid$utm_code #UTM code 
  gadm_prj = output_grid$ctry_shp_prj #The country polygon with relevant projection
  grid = output_grid$grid #The country gridding
  
  #Determining Group IDs and WDPA IDs for all observation units
  print("--Determining Group IDs and WDPA IDs")
  output_group = fn_pre_group(iso = i, wdpa_raw = wdpa_wld_raw,
                              #status = c("Proposed", "Designated", "Inscribed", "Established"),
                              status = NULL,
                            yr_min = yr_min,
                            path_tmp = tmp_pre, utm_code = utm_code,
                            buffer_m = buffer_m, data_pa = data_pa,
                            gadm_prj = gadm_prj, grid = grid, 
                            gridSize = gridSize,
                            log = log,
                            save_dir = save_dir)
  if(output_group$is_ok == FALSE) {next} else grid_param = output_group$grid.param

  #Calculating outcome and other covariates for all observation units
  print("--Calculating outcome and other covariates")
  output_mf = 
    fn_pre_mf_parallel(grid.param = grid_param, 
                       path_tmp = tmp_pre, 
                       iso = i,
                       yr_first = yr_first, yr_last = yr_last,  
                       log = log,
                       save_dir = save_dir)  
  if(output_mf$is_ok == FALSE) {next}                                            
  
  #Remove files in the session memory, to avoid saturation
  tmp_files = list.files(tmp_pre, include.dirs = T, full.names = T, recursive = T)
  file.remove(tmp_files)
                                  
}                            
  
  #End timer for pre-processing
  toc_pre = toc()
  
  #Append the log
  cat(paste("END OF PRE-PROCESSING :", toc_pre$callback_msg, "\n\n"), 
      file = log, append = TRUE)
```

### POST-PROCESSING
 The analysis is designed to analyze a portfolio of PA in different countries, using loop over countries and over PA. To better understand a function, or identify and debug an error, a good practice is to enter the loops using a single country or PA. Thus, it is possible to run the analysis step by step, and even enter into the fuakira nctions to understand what is done « behind the doors ». For instance in « 02_matching.Rmd), set value i = « COM » in the first loop and j = 313046 to peform the analysis step by step for PA with WDPA ID 313046 in Comoros.
```{r message=FALSE, warning=FALSE, eval = FALSE}


# i="MDG"
# j="352249"

  
           
#For each country in the list, the different steps of the post-processing are performed, and duration of the processing computed
count_i = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_post = tic() #start timer
# Initialize two dataframes to record matching quality assessment : matched control and treated units, matched and unmatched treated
df_quality_ct = data.frame() #For treated and control
df_quality_tt = data.frame() #For treated units, before and after matching
#Initialize a dataframe to store the PA in inputs and outputs of the post-processing. Useful to assess the potential loss during pre-processing and post-processing
df_list_post_in = data.frame()
df_list_post_out = data.frame()

#Append the log, and specify matching parameters and quality assessment
cat(paste("##########\nPOST-PROCESSING\n##########\n\nPARAMETERS :\nMatching\n#Parameters\n##Method :", match_method, "\n##Automatic cutoffs :", cutoff_method, "\n##Is it K2K matching ?", is_k2k, "\n##K2K method :", k2k_method, "\n#Quality assessement\n##Absolute standardized mean difference (threshold)", th_mean, "\n##Variance ratio between", th_var_min, "and", th_var_max, "\n\n"), 
    file = log, append = TRUE)
  
# Perform post-processing steps country-by-country, area-by-area
## Loop over country
for (i in list_iso)
{
  #Update counter and show progress
  count_i = count_i+1
  print(paste0(i, " : country ", count_i, "/", max_i))
  
  #Append the log to track progress of the process on country i
  cat(paste("#####\nCOUNTRY :", i, "\n"), file = log, append = TRUE)
  
  #Initialize a dataframe to record matching quality assessment at country level
  df_quality_ct_i = data.frame()
  df_quality_tt_i = data.frame()
  
  #Load the matching frame, and report loaded PA in a dataframe
  print("--Loading the matching frame")
  output_load = fn_post_load_mf(iso = i, 
                           yr_min = yr_min,
                           log = log,
                           load_dir = load_dir,
                           save_dir = save_dir)
  if(output_load$is_ok == FALSE) {next} else mf_ini = output_load$mf
  
  list_pa_in = unique(mf_ini[mf_ini$wdpaid != 0, ]$wdpaid)
  df_list_post_in = rbind(df_list_post_in, data.frame("iso3" = rep(i, length(list_pa_in)),
                                                   "wdpaid" = list_pa_in))
  
    #Append the log : list of PAs analyzed in the matching frame
  cat(paste("LIST OF WDPAIDs :", paste(list_pa_in, collapse = ", "), "\n#####\n\n"), 
      file = log, append = TRUE)
    
  #Initialization
  ##Counter
  count_j = 0
  max_j = length(list_pa_in)
  ##List of control and treatment pixels matched
  df_pix_matched = data.frame()
  
  #Loop over the different PAs
  for (j in list_pa_in)
  {
    #Update counter and show progress
    count_j = count_j+1
    print(paste0("WDPAID : ", j, " : ", count_j, "/", max_j))
    
    #Append the log to track progress of the process on PA j
    cat(paste("###\nWDPAID :", j, "\n###\n\n"), file = log, append = TRUE)
  
    #In the matching frame, select control units and treated units in the PA of interest
    mf_ini_j = mf_ini %>%
      filter(group == 2 | (group == 3 & wdpaid == j))
    
    #Add average forest cover and forest cover loss before treatment
    print("--Add covariates : pre-treatment average forest loss and cover")
    output_add_cov = fn_post_fl_fc_pre_treat(mf = mf_ini_j, 
                                             log = log)
    if(output_add_cov$is_ok == FALSE) {next} else mf_j = output_add_cov$mf
    
    #Run Coarsened Exact Matching
    print("--Run CEM")
    # output_cem = fn_post_match_auto(mf = mf_j, iso = i, 
    #                                dummy_int = FALSE,
    #                                match_method = match_method,
    #                                cutoff_method = cutoff_method,
    #                                is_k2k = is_k2k,
    #                                k2k_method = k2k_method,
    #                                  th_mean = th_mean, 
    #                                  th_var_min = th_var_min, th_var_max = th_var_max,
    #                                colname.travelTime = colname.travelTime, 
    #                                colname.clayContent = colname.clayContent, 
    #                                colname.elevation = colname.elevation,
    #                                colname.tri = colname.tri, 
    #                                colname.fcAvg = colname.fcAvg, 
    #                                colname.flAvg = colname.flAvg,
    #                                #colname.biome = colname.biome,
    #                                log = log)
    output_cem = fn_post_match_nearest_maha_replace(mf = mf_j, iso = i,
                                   dummy_int = FALSE,
                                   is_k2k = is_k2k,
                                   k2k_method = k2k_method,
                                     th_mean = th_mean,
                                     th_var_min = th_var_min, th_var_max = th_var_max,
                                   colname.travelTime = colname.travelTime,
                                   colname.clayContent = colname.clayContent,
                                   colname.elevation = colname.elevation,
                                   colname.tri = colname.tri,
                                   colname.fcAvg = colname.fcAvg,
                                   colname.flAvg = colname.flAvg,
                                   #colname.biome = colname.biome,
                                   log = log)
    if(output_cem$is_ok == FALSE){next} else out_cem_j = output_cem$out.cem
    
    ##Add matching quality metrics of the PA matched in this iteration
    tbl.quality.ct.j = output_cem$tbl.quality
    df_quality_ct = rbind(df_quality_ct, tbl.quality.ct.j) 
    
    #Plots : covariates
    print("--Some plots : covariates")
    print("----Covariate balance")
    output_covbal = fn_post_covbal(out.cem = out_cem_j,
                                   tbl.quality = tbl.quality.ct.j,
                   mf = mf_j,
                   colname.travelTime = colname.travelTime, 
                   colname.clayContent = colname.clayContent,
                   colname.fcAvg = colname.fcAvg, 
                   colname.flAvg = colname.flAvg,
                   colname.tri = colname.tri,
                   colname.elevation = colname.elevation,
                  # colname.biome = colname.biome,
                   th_mean = th_mean,
                   iso = i,
                   path_tmp = tmp_post,
                   wdpaid = j,
                   log = log,
                   save_dir = save_dir)
  if(output_covbal$is_ok == FALSE) {next}
    
    print("----Density plots and histograms")
    #Density plots
    output_density = fn_post_plot_density(out.cem = out_cem_j,  
                                         mf = mf_j,
                                         colname.travelTime = colname.travelTime, 
                                         colname.clayContent = colname.clayContent,
                                         colname.fcAvg = colname.fcAvg, 
                                         colname.flAvg = colname.flAvg,
                                         colname.tri = colname.tri,
                                         colname.elevation = colname.elevation,
                                        # colname.biome = colname.biome,
                                         iso = i,
                                         path_tmp = tmp_post,
                                         wdpaid = j,
                                         log = log,
                                         save_dir = save_dir)
     if(output_density$is_ok == FALSE) {next}
    #Histograms
    output_hist = fn_post_plot_hist(out.cem = out_cem_j,  
                                     mf = mf_j,
                                     colname.travelTime = colname.travelTime, 
                                     colname.clayContent = colname.clayContent,
                                     colname.fcAvg = colname.fcAvg, 
                                     colname.flAvg = colname.flAvg,
                                     colname.tri = colname.tri,
                                     colname.elevation = colname.elevation,
                                  #   colname.biome = colname.biome,
                                     iso = i,
                                     path_tmp = tmp_post,
                                     wdpaid = j,
                                     log = log,
                                     save_dir = save_dir)
     if(output_hist$is_ok == FALSE) {next}
    
    #Panelize dataframes
    print("----Panelize (Un-)Matched Dataframe")
    output_panel = fn_post_panel(out.cem = out_cem_j, 
                                  mf = mf_j,  
                                  iso = i,
                                  wdpaid = j,
                                  log = log,
                                 save_dir = save_dir)
     if(output_panel$is_ok == FALSE) {next}
    
    matched.wide.j = output_panel$matched.wide
    unmatched.wide.j = output_panel$unmatched.wide
    matched.long.j = output_panel$matched.long
    unmatched.long.j = output_panel$unmatched.long 
    
    #Assess the difference between matched and unmatched treated units
    print("----Statistics on treated units before and after matching")
    
    output_m_unm_treated = fn_post_m_unm_treated(df_m = matched.wide.j,
                                                 df_unm = unmatched.wide.j,
                                                 iso = i,
                                                 wdpaid = j,
                                                 th_mean = th_mean, 
                                                 th_var_min = th_var_min, 
                                                 th_var_max = th_var_max,
                                                 save_dir = save_dir,
                                                 log = log)
    if(output_m_unm_treated$is_ok == FALSE) {next}
    
    ##Add matching quality metrics of the PA matched in this iteration
    tbl.quality.tt.j = output_m_unm_treated$tbl.quality
    df_quality_tt = rbind(df_quality_tt, tbl.quality.tt.j) 
    
    #Extract matched units and plot them on a grid
    print("----Extract matched units and plot them on a grid")
    ##Extract ID of treated and control pixels
    df_pix_matched_j = matched.wide.j %>%
      st_drop_geometry() %>%
      as.data.frame() %>%
      dplyr::select(c(group, assetid)) %>%
      rename("group_matched" = "group") 
    df_pix_matched = rbind(df_pix_matched, df_pix_matched_j)
    
    ##Plot the grid with matched control and treated for the PA
    output_grid = fn_post_plot_grid(iso = i, wdpaid = j,
                      is_pa = TRUE,
                      df_pix_matched = df_pix_matched_j,
                      path_tmp = tmp_post,
                      log = log,
                      load_dir = load_dir,
                      save_dir = save_dir)
     if(output_grid$is_ok == FALSE) {next}

    #Plots the evolution of forest cover for treated and control units, before and after matching
    print("----Plots again : trend")
    #/!\ 27/10/2023 : I have removed the plot for unmatched units : take too much time and useless for the next presentations we have to do !
    output_trend = fn_post_plot_trend(matched.long = matched.long.j, 
                       unmatched.long = unmatched.long.j, 
                       mf = mf_j,
                       data_pa = data_pa,
                       iso = i,
                       wdpaid = j,
                       log = log,
                       save_dir = save_dir)
    if(output_trend$is_ok == FALSE) {next}
    
    #The PA has gone through all post-processing steps : report it in the output dataframe
    df_list_post_out = rbind(df_list_post_out, data.frame("iso3" = i, "wdpaid" = j)) 

  }
    
  # Plot the grid with matched control and treated for the country 
  output_grid = fn_post_plot_grid(iso = i, wdpaid = j,
                    is_pa = FALSE,
                    df_pix_matched = df_pix_matched,
                    path_tmp = tmp_post,
                    log = log,
                    load_dir = load_dir,
                    save_dir = save_dir)
   if(output_grid$is_ok == FALSE) {next}
  
}       

#Save the dataframe on matching quality
##Matched control and treated units
aws.s3::s3write_using(
FUN = data.table::fwrite,
df_quality_ct,
object = paste(save_dir, "df_quality_ct.csv", sep = "/"),
bucket = "projet-afd-eva-ap",
opts = list("region" = ""))
##Treated units, before and after matching
aws.s3::s3write_using(
FUN = data.table::fwrite,
df_quality_tt,
object = paste(save_dir, "df_quality_tt.csv", sep = "/"), 
bucket = "projet-afd-eva-ap",
opts = list("region" = ""))
#Save the dataframes reporting PAs in input and output of post-processing
##Input
aws.s3::s3write_using(
FUN = data.table::fwrite,
df_list_post_in,
object = paste(save_dir, "df_list_post_in.csv", sep = "/"),
bucket = "projet-afd-eva-ap",
opts = list("region" = ""))
##Output
aws.s3::s3write_using(
FUN = data.table::fwrite,
df_list_post_out,
object = paste(save_dir, "df_list_post_out.csv", sep = "/"),
bucket = "projet-afd-eva-ap",
opts = list("region" = ""))

#End post-processing timer
toc_post = toc()

#Append the log and save it
cat(paste("END OF POST-PROCESSING :", toc_post$callback_msg, "\n\n"),
    file = log, append = TRUE)
aws.s3::put_object(file = log,
                   bucket = paste("projet-afd-eva-ap", save_dir, sep = "/"),
                   region = "",
                   show_progress = FALSE)  
                 
```
