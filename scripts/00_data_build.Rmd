# Building the datasets

This script builds the different datasets for the analysis. The lists of protected areas (PAs) reported by the Agence Française de Développement (AFD) departments are combined, merged with AFD project database ("SIOP") and the World Database on Protected Areas (WDPA). The latter is the most comprehensive database on marine and terrestrial protected areas, published by the International Union for the Conservation of Nature (IUCN). The following datasets are created :

-   A confidential dataset to perform descriptive statistics on fundings

-   A dataset to perform non-confidential statistics

-   Datasets specific to impact analysis (for PA supported by the AFD or a specific funder, a all PA in a given country, etc.)

-   Datasets with geospatial information, for specific uses (e.g maps)

-   Datasets with total area at country, region or world level, taking into account potential intersection between PA reported by the WDPA (see WDPA documentation)

These datasets are available upon requests, with potential restriction for datasets containing confidential data. Note that this script loads geospatial datasets that are memory demanding. Ensure that the R session has accessed to enough temporary memory (RAM) before running the script (typically 10 GB), or clean the RAM regularly.

The datasets used are stored and saved into the SSPCloud platform that uses minIO storage. Thus specific functions from the aws.S3 package are used to write and read files (aws.S3::s3read_using() and aws.S3::s3write_using()). These can be replaced by other R functions to read/write locally (data.table::fread() typically).

## Initial settings

Configuring the Rmarkdown

\#`{r setup, include = FALSE, eval = FALSE} #knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) #`

Downloading and importing the relevant packages

```{r message=TRUE, warning=TRUE, eval = FALSE, class.source = "fold-show"}
install.packages(c("janitor", "geodata", "wdpar", "countrycode","dplyr"))
library(tidyverse)
library(dplyr)
library(data.table)
library(readxl)
library(janitor)
library(stringi)
library(sf)
library(terra)
library(mapview)
library(wdpar)
library(aws.s3)
library(countrycode)
library(geodata)

#Install webdriver to download WDPA data
#webdriver::install_phantomjs()

```

## Datasets for analysis

### Merge PAs reporting by AFD technical departments

A first step has been to collect information on the PAs funded by the AFD. A first bunch was collected by Léa Poulin, Ingrid Dallmann and Pierre-Yves Durand (from evaluation and learning service of the innovation, research and knowledge department). Others were reported to us by the agriculture, rural development and biodiversity department. These datasets are combined with only relevant variables for future merging with WDPA and SIOP databases.

```{r, eval = FALSE, class.source = "fold-show"}
#PAs gathered by the evaluation department
##BDD_joint created by Léa Poulin. 
##Create a dataset with a merged column for cofunders, instead of a variable for each. Only relevant variables are kept, and the date/author of the report are added.
data_pa_eva = 
  #read_excel("data_raw/BDD_joint.xlsx") %>%
  s3read_using(readxl::read_excel,
               object = "data_raw/BDD_joint.xlsx",
               bucket = "projet-afd-eva-ap",
               opts = list("region" = "")) %>%
  as.data.frame() %>%
  unite(cofinanciers, starts_with("cofinancier"),
        sep=",", remove = TRUE, na.rm = TRUE) %>%
  select(c(id_projet, id_concours, cofinanciers, 
           nom_ap, wdpaid, superficie)) %>%
  rename("superficie_km2" = "superficie") %>%
  mutate(superficie_km2 = as.numeric(superficie_km2),
         wdpaid = as.numeric(wdpaid),
         date_entree = "2022-12-06",
         auteur_entree = "Léa Poulin,Pierre-Yves Durand,Ingrid Dallmann") %>%
  # Change encoding of characters
  mutate(across(.cols = !c(wdpaid, superficie_km2),
                .fns = ~stri_enc_toutf8(.x)))

##WDPAID 797 with ID project CZZ3056 corresponds to APAC de Kawawana in Senegal, with no WDPAID (https://kawawana.iccaconsortium.org/) 
data_pa_eva[data_pa_eva$wdpaid == "797" & data_pa_eva$id_projet == "CZZ3056",]$nom_ap = "APAC de Kawawana"
#Change reported area (https://kawawana.iccaconsortium.org/?p=150) : 10 000 ha or 100 km2
data_pa_eva[data_pa_eva$wdpaid == "797" & data_pa_eva$id_projet == "CZZ3056",]$superficie_km2 = 100
data_pa_eva[data_pa_eva$wdpaid == "797" & data_pa_eva$id_projet == "CZZ3056",]$wdpaid = NA

#PAs gathered by agriculture, rural development and biodiversity department (10-08-2023)
data_pa_arb = 
  #read_excel("data_raw/BDD_ARB_10082023.xlsx") %>%
  s3read_using(readxl::read_excel,
             object = "data_raw/BDD_ARB_10082023.xlsx",
             bucket = "projet-afd-eva-ap",
             opts = list("region" = "")) %>%
  as.data.frame() %>%
  clean_names() %>%
  select(c(id_projet, id_concours, nom_cofinanciers,
           nom_de_laire_protegee, id_wdpa, superficie_km2)) %>%
  rename("cofinanciers" = "nom_cofinanciers",
         "nom_ap" = "nom_de_laire_protegee",
         "wdpaid" = "id_wdpa",
         "superficie_raw" = "superficie_km2") %>%
  #Create variables:
  ## Replace "NA" by NA values in wdpaid
  ## Check unit of area given reported by ARB
  ## Convert the area reported in km2, controlling for NA values, unreported values ("Non requis (information délivrée par la WDPA)"), values in hectares or km2. Note in some rows, unit must be removed and "," replaced by "." for the numeric conversion
  mutate(wdpaid = as.numeric(case_when(wdpaid == "NA" ~ NA,
                            TRUE ~ wdpaid)),
         date_entree = "2023-08-10",
         auteur_entree = "ARB",
         superficie_unit = case_when(grepl("km2", superficie_raw) ~ "km2",
                                     grepl("ha|Ha", superficie_raw) ~ "ha",
                                     TRUE ~ "km2"),
         superficie_km2 = case_when(grepl("Non", superficie_raw) ~ NA,
                                is.na(superficie_raw) ~ NA,
                                superficie_unit == "ha" ~ as.numeric(gsub(",", ".", gsub("ha|Ha", "", superficie_raw)))/1e2,
                                superficie_unit == "km2" ~ as.numeric(gsub(",", ".", gsub("km2", "", superficie_raw))),
                                TRUE ~ as.numeric(superficie_raw))) %>%
  # Change encoding of characters
  mutate(across(.cols = !c(wdpaid, superficie_km2),
                .fns = ~stri_enc_toutf8(.x))) %>%
  select(c("id_projet", "id_concours", "cofinanciers", "nom_ap",
           "wdpaid", "superficie_km2", "date_entree", "auteur_entree"))
  
#Create a dataset gathering the previous datasets
data_pa_afd = rbind(data_pa_eva, data_pa_arb)

#Finally, writing the dataset in csv file. Careful to the delimiter : ";" used as "," present in some variables values.
# write_delim(data_pa_afd, "data_raw/BDD_PA_AFD.csv",
#             delim = ";",
#             na = "NA")
# s3write_using(x = data_pa_afd,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_raw/BDD_PA_AFD.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### Merge the list of PAs to AFD project information and WDPA

The list of PAs reported by AFD departments are then merged with AFD internal project information database (so-called "SIOP") and the World Database on Protected areas.

```{r, eval = FALSE}

#Import the list of PAs
data_pa_afd = 
  #read_delim("data_raw/BDD_PA_AFD.csv", delim = ";")
  s3read_using(readr::read_delim,
                delim = ";", #Careful to the delimiter choice
               show_col_types = FALSE,
                object = "data_raw/BDD_PA_AFD.csv",
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))

list_wdpa_afd = unique(data_pa_afd$wdpaid)

#Import SIOP extract
##A function to transform country names from upper case (SIOP database) to lower cases : FRANCE -> France
fn_ucfirst <- function (str) {
  paste(toupper(substring(str, 1, 1)), tolower(substring(str, 2)), sep = "")
}

data_siop_pa = 
  #read_excel("data_raw/BO_AP_16082023.xlsx") %>%
  s3read_using(readxl::read_excel,
              object = "data_raw/BO_AP_16082023.xlsx",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  #Keep only project IDs corresponding to PAs reported
  filter(id_projet %in% data_pa_afd$id_projet) %>%
  dplyr::select(c(id_projet, id_concours,
           libelle_court_direction_regionale,
           pays_de_realisation, autres_pays_de_realisation,
           mt_fin_global_af_d_prevu_devise,
           montant_prevu_concours_euro_octroi,
           mt_global_projet_prevu_devise,
           cofinancier,
           mt_part_cofinancier_prevu_euro,
           libelle_produit,
           date_doctroi_projet, annee_doctroi_projet)) %>%
  rename("cofinanciers_siop" = "cofinancier",
         "pays" = "pays_de_realisation",
         "pays2" = "autres_pays_de_realisation") %>%
  #Change country ("pays") name from upper case to lower case : e.g FRANCE -> France 
  mutate(pays = case_when(is.na(pays) == TRUE ~ NA,
                         is.na(pays) == FALSE ~ fn_ucfirst(pays)),
         pays2 = case_when(is.na(pays2) == TRUE ~ NA,
                          is.na(pays2) == FALSE ~ fn_ucfirst(pays2))) %>%
  #Add ISO code from countrycode package, reading "pays" variable
  mutate(iso3_siop = countrycode(sourcevar = pays, 
                                 origin = "country.name.fr",
                                 destination = "iso3c",
                                 custom_match = c("Multi-pays" = "ZZ",
                                                  "Multi-Pays" = "ZZ",
                                                  "Inde" = "IND")),
         .after = "pays")
  
#Import WDPA data
##Download the latest version of the WDPA and write to the storage, if necessary
# data_wdpa = wdpa_fetch(x = "global", wait = TRUE, download_dir = "data_raw",
#                        page_wait = 2, verbose = TRUE)
# st_write(wdpa,
#          dsn = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
#          delete_dsn = TRUE)

##Load the WDPA from the storage
data_wdpa = 
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  st_drop_geometry() %>%
  clean_names() %>%
  filter(wdpaid %in% list_wdpa_afd) %>%
  rename("iso3_wdpa" = "iso3")

#Merge the datasets
##A first raw dataset that will be edited to complete ISO3 code of countries.
data_raw1 = data_pa_afd %>%
  #Add information from WDPA to PAs funded and with WDPAID
  left_join(data_wdpa, by = "wdpaid") %>%
  #Add information from SIOP
  left_join(data_siop_pa, by = c("id_projet", "id_concours")) %>%
  #Keep only one ISO information : priority WDPA, then SIOP if NA value
  mutate(iso3 = iso3_wdpa,
         iso3 = case_when(is.na(iso3) == TRUE ~ iso3_siop,
                          TRUE ~ iso3),
         .after = "iso3_wdpa")

#Manually add iso3 for some PAs where names are known but assigned "ZZ". 
#The nom_ap is searched on google ("nom_ap protected area") and iso3 completed if
#information found
data_raw2 = data_raw1 %>%
  mutate(iso3 = case_when(grepl("Yambé-Diahoué", nom_ap) ~ "NCL",
                          nom_ap == "Aitutaki (3 Ra'ui)" ~ "COK",
                          nom_ap == "Dohimen (Hienghène)" ~ "NCL",
                          nom_ap == "Kerehira" ~ "SLB",
                          nom_ap == "Kiribati" ~ "KIR",
                          nom_ap == "Marou" ~ "VUT",
                          nom_ap == "Mistery Island (Aneityum)" ~ "VUT",
                          nom_ap == "Ngula Pele" ~ "VUT",
                          nom_ap == "Paonangisu" ~ "VUT",
                          nom_ap == "Parc provincial Yeega-Hienga (Hienghène)" ~ "NCL",
                          grepl("Rarotonga", nom_ap) ~ "COK",
                          nom_ap == "Saama" ~ "VUT",
                          nom_ap == "Siviri" ~ "VUT",
                          nom_ap == "Dohimen" ~ "NCL",
                          nom_ap == "Hienghène" ~ "NCL",
                          nom_ap == "Hyabe Lé Jao" ~ "NCL",
                          grepl("Pouébo", nom_ap) ~ "NCL",
                          nom_ap == "Tasi Vanua" ~ "VUT",
                          nom_ap == "Yeega" ~ "NCL",
                          nom_ap == "Mangareva" ~ "PYF",
                          nom_ap == "Rakiraiki" ~ "FJI",
                          nom_ap == "Tasi Vanua" ~ "VUT",
                          nom_ap == "Parc National Pongara" ~ "GAB",
                          TRUE ~ iso3))

#Save this raw dataset
# s3write_using(x = data_raw2,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_raw/BDD_PA_raw.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

### Correct errors

Here errors in the reported information are corrected manually. Note the SIOP can be updated and the error not present anymore. The errors that do not need to be corrected anymore are kept in comment.

```{r, eval = FALSE}
#Loading the raw dataset
data_raw = 
  #fread("data_raw/BDD_PA_raw.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_raw/BDD_PA_raw.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))
data_raw_corr = data_raw

#Modify errors in the dataset
##4223, 4224, 4226, 4228, 4229 : all in PS-N.Caledonie
## -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("4223", "4224", "4226", "4228", "4229") & data_raw_corr$pays == "Fidji",]$pays = "P-S N.Caléd"
##305082 : Vanuatu instead of Fidji
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("305082") & data_raw_corr$pays == "Fidji",]$pays = "Vanuatu"
##31459 : Central African Republic instead of Cameroon. 
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("31459") & data_raw_corr$pays == "Cameroun",]$pays = "Centrafrique"
##Rio Grande de Buba : Guinee Bissau instead of Gambia
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("317051") & data_raw_corr$pays == "Gambie",]$pays = "Guinee-Bissau"
##WDPAID 20267 : in GNQ instead of GIN
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("20267") ,]$pays = "Guinee-Equatoriale"
# data_raw_corr[data_raw_corr$wdpaid %in% c("20267") ,]$iso3 = "GNQ"

# s3write_using(x = data_raw_corr,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_raw/BDD_PA_raw_corr.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

### Tidy the datasets

After manual correction, a tidy dataset is built. Relevant variables are selected, region/sub-region/country names are added from ISO3 codes and countrycode package, description of IUCN categories added. Some variables are renamed in English.

```{r, eval = FALSE}
#Import raw dataset corrected from report errors
data_raw_corr = 
  #fread("data_raw/BDD_PA_raw_corr.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_raw/BDD_PA_raw_corr.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

#Build the tidy dataset
data_tidy = data_raw_corr %>%
  #Select relevant variables
  select(c(libelle_court_direction_regionale, pays, pays2, parent_iso3, iso3,
           id_projet, id_concours, nom_ap, wdpaid, wdpa_pid, 
           date_doctroi_projet, annee_doctroi_projet, status, status_yr,
           iucn_cat, marine, superficie_km2, rep_m_area, rep_area,
           gov_type, own_type,
           cofinanciers, cofinanciers_siop,
           mt_fin_global_af_d_prevu_devise,
           montant_prevu_concours_euro_octroi,
           mt_global_projet_prevu_devise,
           mt_part_cofinancier_prevu_euro,
           libelle_produit,
           date_entree, auteur_entree)) %>%
    #Create dummy variables for main investors
  #AFD is always funder, so no need of a dummy. 
  mutate(kfw_bin = grepl("KFW|kfw|KfW", cofinanciers),
         ffem_bin = grepl("ffem|FFEM", cofinanciers),
         cof_bin = is.na(cofinanciers) == FALSE & !(cofinanciers %in% c("AFD", "afd")),
         .after = "cofinanciers") %>%
  #Create an area variable combining AFD and WDPA information. Priority given to WDPA, then AFD if unknown
  rename("area_afd_km2" = "superficie_km2") %>%
  #If both are not NA and different, take rep_area
  #If both are equal, take rep_area
  #if one is NA, take the other
  #If both NA, set NA
  #If rep_area = 0 and area_afd_km2 != 0 then set area_afd_km2
  mutate(area_km2 = case_when(is.na(area_afd_km2) == FALSE & is.na(rep_area) == FALSE & area_afd_km2 == rep_area ~ rep_area,
                              is.na(area_afd_km2) == FALSE & is.na(rep_area) == FALSE & area_afd_km2 != rep_area ~ rep_area,
                              is.na(area_afd_km2) == TRUE & is.na(rep_area) == FALSE ~ rep_area,
                              is.na(area_afd_km2) == FALSE & is.na(rep_area) == TRUE ~ area_afd_km2,
                              is.na(area_afd_km2) == TRUE & is.na(rep_area) == TRUE ~ NA,
                              rep_area == 0 & is.na(area_afd_km2) == FALSE & area_afd_km2 >0 ~ area_afd_km2
                              ),
         .after = "rep_area") %>%
    #Some entries in "pays" are French department, DROM-COM, "Ocean Indien" or   
  #"Multi-Pays".
  #French related : the ISO3 code 
  #Ocen Indien let NA value, Muti-pays set to ZZ as in the SIOP dataset
  #Nouvelle-Calédonie is divided in two provinces : north and south. This subdivision is irrelevant in our analysis so we keep only "Nouvelle Caledonie"
  mutate(iso3 = case_when(
    pays == "Mayotte" ~ "MYT",
    pays == "Nouvelle-Caledonie" ~ "NCL",
    pays == "Polynesie Francaise" ~ "PYF",
    is.na(iso3) & pays %in% c("Multi-Pays", "Multi-pays", "Ocean Indien") ~ "ZZ",
    TRUE ~ iso3)) %>%
  #Add region, sub-region and country names from the ISO3 country code
  mutate(region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.region.name",
                              custom_match = c("COG;CMR;CAF" = "Africa",
                                               "ZZ" = "")),
         sub_region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.regionsub.name",
                              custom_match = c("COG;CMR;CAF" = "Sub-Saharan Africa",
                                               "ZZ" = "")),
         country_en = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.en",
                              custom_match = c("PYF" = "French Polynesia",
                                               "NCL" = "New Caledonia",
                                               "MYT" = "Mayotte",
                                               "COK" = "Cook Islands",
                                               "ZZ" = "Multi-countries",
                                               "COG;CMR;CAF" = "Multi-countries")),
         country_fr = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.fr",
                              custom_match = c("PYF" = "Polynésie Française",
                                               "NCL" = "Nouvelle-Calédonie",
                                               "MYT" = "Mayotte",
                                               "COK" = "Iles Cook",
                                               "ZZ" = "Multi-pays",
                                               "COG;CMR;CAF" = "Multi-pays")),
         .after = "iso3") %>%
#Change transboundary iso3 to ZZ (multi-countries)
  mutate(iso3 = case_when(iso3 == "COG;CMR;CAF" ~"ZZ",
                          TRUE ~iso3)) %>%
    #Some PAs have iso "ZZ" (multi-countries) by funded by Dr Ocean Pacifique. The region is assigned to Oceania
    mutate(region = case_when(region == "" & libelle_court_direction_regionale == "DR OCEAN PACIFIQUE" ~ "Oceania",
                              region == "" & grepl("sahel|guinee|africa", libelle_court_direction_regionale, ignore.case = TRUE) ~ "Africa",
                              region == "" & grepl("chine|asie", libelle_court_direction_regionale, ignore.case = TRUE) ~ "Asia",
                              region == "" & grepl("amerique", libelle_court_direction_regionale, ignore.case = TRUE) ~ "America",
                              region == "" ~ NA,
                            TRUE ~ region)) %>%
  #Add the description of IUCN from its category 'in French and English)
    mutate(iucn_des_fr = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national", 
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
      mutate(iucn_des_en = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Strict nature reserve",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Wilderness area",
  !is.na(wdpaid) & iucn_cat == "II" ~ "National park",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Natural monument or feature",
  !is.na(wdpaid) & iucn_cat == "IV" ~ " Habitat or species management area",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Protected landscape or seascape",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Protected area with sust. use of nat. res.",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Not categorized",
  TRUE ~ "Not referenced"), .after = iucn_cat) %>%
    #Modify class of some variables
  mutate(across(.cols = -c("wdpaid", "area_afd_km2", 
                           "area_km2", "rep_area", "rep_m_area",
                           "annee_doctroi_projet",
                          "mt_fin_global_af_d_prevu_devise",
                          "montant_prevu_concours_euro_octroi" ,
                          "mt_global_projet_prevu_devise",
                          "mt_part_cofinancier_prevu_euro"), 
                .fns = ~stri_enc_toutf8(.x))) %>%
  #Translate names in English
  rename("region_afd" = "libelle_court_direction_regionale",
         "name_pa" = "nom_ap",
         "date_funding" = "date_doctroi_projet",
         "year_funding" = "annee_doctroi_projet")


```

### Dataset with only AFD project variables

Build a dataset from the tidy dataset that keeps only SIOP variables. Potentially useful for analysis on SIOP information.

```{r, eval = FALSE}
#Select info corresponding to SIOP extract and AP 
list_var_siop = c("id_projet", "id_concours", "region_afd", "pays", "pays2", 
                  "date_funding", "year_funding", "cofinanciers_siop",
                  "mt_fin_global_af_d_prevu_devise" ,
                  "montant_prevu_concours_euro_octroi",
                  "mt_global_projet_prevu_devise",
                  "mt_part_cofinancier_prevu_euro",
                  "libelle_produit", "date_entree", "auteur_entree" )

#Definining dataset for future work with dataset other than WDPA 
data_siop_tidy = data_tidy %>%
  dplyr::select(all_of(list_var_siop))

#write_csv(data_siop_tidy, "data_tidy/BDD_siop_tidy.xlsx")
# s3write_using(x = data_siop_tidy,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_tidy_siop.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### Dataset for non-confidential analysis

Build a dataset with one row per PA. In the list of PAs reported by AFD department, some PAs are also reported in the WDPA and are identified by a unique WDPA ID, some have no WDPAID but have a unique name, and other have neither name nor WDPAID. For the latter case, a PA is supposed to be identified by project ID and country. Thus we need to remove duplicates for each case. Also, all the funding years of each PA is kept. Note that a few PAs have an entry with WDPA ID, and an other with no WDPAID though they have the same name (e.g Parc National de Pongara). The duplicate without WDPA ID is removed.

For the impact analysis, we also need to take into account transboundary PAs (i.e PAs on more than one country). Indeed the analysis is performed country by country. Thus we need to divide the PAs across the countries it is located in, and re-compute the area of the PA in each country.

#### For descriptive statistics

```{r, eval = FALSE}
#Listing relevant variables for analysis that are NOT confidential (i.e not concern funding)
list_var_fund = c("cofinanciers", "cofinanciers_siop",
                  "mt_fin_global_af_d_prevu_devise",
                  "montant_prevu_concours_euro_octroi",
                  "mt_global_projet_prevu_devise",
                  "mt_part_cofinancier_prevu_euro",
                  "libelle_produit",
                  "kfw_bin", "ffem_bin", "cof_bin")

#Defining dataset for descriptive statistics
data_nofund = data_tidy %>%
  select(!all_of(list_var_fund))

#fwrite(data_nofund, "data_tidy/BDD_PA_AFD_nofund.csv")
# s3write_using(x = data_nofund,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_nofund.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#Then to keep only one row per PA, we need to consider separately PAs having WDPA ID and PAs which do not.

## Observations with WDPAID
###We keep information on fundings : one row for each wdpa_pid, funding year is kept
###Note that WDPA_PID is a unique identifier for zones inside the corresponding WDPAID. The choice of the WDPA_PID to keep is performed below (e.g choosing the area instead of the buffer zone)
data_nofund_wdpa = data_nofund %>%
  subset(is.na(wdpaid) == FALSE) %>%
  group_by(wdpa_pid, year_funding) %>%
  slice(1) %>%
  ungroup() %>%
  group_by(wdpa_pid) %>%
  #Then we create a variable with all the funding year for each WDPA ...
  mutate(year_funding_all = paste0(year_funding, collapse = ","),
         .after = "year_funding") %>%
  #... and keep only the earlier funding year for year_funding
  arrange(year_funding) %>%
  slice(1) %>%
  #Rename year_funding variable to precise it is the year of first funding by the AFD
  rename("year_funding_first" = "year_funding") %>%
  ungroup() %>%
  #Finally, we need to manually remove lines with more than one WDPA_PID
  ## Remove the marine area of WDPAID 9035 with null area
  filter(!(wdpa_pid == "9035_A")) %>%
  ## 555547861 has 3 marine PAs. The C one is chosen as the size reported by AFD (superficie_km2) matches the area reported by WDPA (https://www.protectedplanet.net/555547861)
  filter(!(wdpa_pid %in% c("555547861_A", "555547861_B"))) %>%
  # 555705345 : buffer area is also reported. Remove the buffer
  filter(!(wdpa_pid == "555705345_B")) %>%
  #555547863 : keep the WDPA_PID whose area matches the one reported by AFD employees and WDPA website (https://www.protectedplanet.net/555547863)
  filter(!(wdpa_pid == "555547863_A"))
  
# info_filtering = filter(data_raw_corr, wdpaid %in% c(9035, 555547861, 555547863, 555705345 )) %>%
#   group_by(wdpa_pid) %>%
#   slice(1)

#Observations without WDPAID but with name of the PA
data_nofund_name = data_nofund %>%
  subset(is.na(wdpaid) == TRUE & is.na(name_pa) == FALSE) %>%
  #Remove completely similar rows (due to merging with SIOP and WDPA)
  unique() %>%
  #Some PAs might have been funded at different times. Create a variable with all the funding year for each PA name
  group_by(name_pa) %>%
  mutate(year_funding_all = paste0(unique(year_funding), collapse = ","),
         .after = "year_funding") %>%
  mutate(year_funding_all = case_when(year_funding_all == "NA" ~NA,
                                      TRUE ~ year_funding_all)) %>%
  #keep observation with largest area reported
  arrange(-area_km2) %>%
  slice(1) %>%
  #Change year_funding to min of year_fund_all
  mutate(year_funding = min(as.numeric(unlist(strsplit(year_funding_all, split = ","))), na.rm = TRUE),
         year_funding = case_when(year_funding == Inf ~ NA,
                                  TRUE ~ year_funding)) %>%
  #Rename year_funding variable to precise it is the year of first funding by the AFD
  rename("year_funding_first" = "year_funding") %>%
  ungroup() %>%
  #Some PAs have multiple entries, with DR Siege de Paris and DR Ocean Pacifique. Their region is assigned to Oceania
  mutate(region = case_when(name_pa %in% c("Ailite", "Aitutaki (3 Ra'ui)",
                                               "Kerehira", 
                          "Kibelofolu", "Kiribati", "Ma'au", "Mereka", 
                          "Mistery Island (Aneityum)", "Ngula Pele", "Niu Houa",
                          "Niumarere", "Paonangisu", 
                          "Parc provincial Yeega-Hienga (Hienghène)", 
                          "Rarotonga : Avana-Muri lagoon ra'ui", 
                          "Rarotonga : Mitiaro ra'ui", "Saama", "Siviri", 
                          "Takara", "Takola", "Tavuilo", "Waimamaru") 
           & id_projet == "CZZ1282" ~ "Oceania",
         TRUE ~ region)) 
#Careful : the following filtering are outdated
  # filter(!(grepl("Aire de gestion durable des ressources Yambé", name_pa) & id_projet == "CZZ1282")) %>%
  # ##Remove duplicate with zero area while the other is non-zerp
  # filter(!(id_projet == "CZZ1667" & name_pa == "Dohimen")) %>%
  # filter(!(name_pa == "Hienghène" & id_projet == "CZZ1667")) %>%
  # filter(!(name_pa == "Hyabe Lé Jao" & id_projet == "CZZ1667")) %>%
  # filter(!(name_pa == "Naroko" & id_projet == "CZZ1667")) %>%
  # filter(!(name_pa == "Tasi Vanua" & id_projet == "CZZ166701")) %>%
  # filter(!(name_pa == "Yeega" & id_projet == "CZZ1667")) %>%
  # ##Remove duplicate of Pouébo with area 0
  # filter(!(name_pa == "Pweevo (Pouébo)"))

#Finally, observations with no WDPAID and no name_pa
data_nofund_na = data_nofund %>%
  subset(is.na(wdpaid) == TRUE & is.na(name_pa) == TRUE) %>%
  #Remove identical observations
  unique() %>%
    #Some PAs might have been funded at different times. Create a variable with all the funding year for each PA name
  group_by(id_projet, iso3) %>%
  mutate(year_funding_all = paste0(unique(year_funding), collapse = ","),
         .after = "year_funding") %>%
  mutate(year_funding_all = case_when(year_funding_all == "NA" ~NA,
                                      TRUE ~ year_funding_all)) %>%
  #keep observation with largest area reported
  arrange(-area_km2) %>%
  slice(1) %>%
  #Change year_funding to min of year_fund_all
  mutate(year_funding = min(as.numeric(unlist(strsplit(year_funding_all, split = ","))), na.rm = TRUE),
         year_funding = case_when(year_funding == Inf ~ NA,
                                  TRUE ~ year_funding)) %>%
  #Rename year_funding variable to precise it is the year of first funding by the AFD
  rename("year_funding_first" = "year_funding") %>%
  ungroup() 
  
#Finally bind the datasets
data_nofund_nodupl = rbind(data_nofund_wdpa, data_nofund_name, data_nofund_na) 

#fwrite(data_nofund_nodupl, "data_tidy/BDD_nofund_nodupl.csv")
# s3write_using(x = data_nofund_nodupl,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

#### For impact analysis

Different datasets are built, depending on the portfolio to analyse (e.g PAs supported by AFD or a specific funder).

##### AFD portfolio

One PA in the AFD portfolio is located in Congo Republic, Cameroon and Republican Central Africa (WDPA ID 555547988). As by desing the impact analysis is performed country by country, this PA must be artificially divided in three and each part assigned to the country it is located in.

```{r, eval = FALSE}

#Import the non-confidential dataset with no duplicates
data_pa_nofund_nodupl = 
  #fread("data_raw/BDD_PA_AFD_nofund_nodupl.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

#Import WDPA data
data_wdpa =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  select(c(wdpaid, geom)) %>%
  filter(wdpaid %in% data_pa_nofund_nodupl$wdpaid)

#The PA WDPAID 555547988 is located in COG, CMR and CAF
##Create a frame with one line by country
df_555547988 = data_pa_nofund_nodupl %>%
  filter(wdpaid == 555547988) %>%
  left_join(data_wdpa, by = "wdpaid") %>%
  #Create one line by country
  separate_longer_delim(cols = c("parent_iso3"), delim = ";") %>%
  mutate(iso3 = parent_iso3,
         country_en = countrycode(sourcevar = iso3,
                                  origin = "iso3c",
                                  destination = "un.name.en"),
        country_fr = countrycode(sourcevar = iso3,
                        origin = "iso3c",
                        destination = "un.name.fr"), 
        name_pa = paste(name_pa, iso3, sep = "-"))

##Get countries boundaries from geodata package
ctry_bnd = gadm(country = unique(df_555547988$iso3), 
                path = tempfile(),
                version = "latest", level = 0) %>%
  st_as_sf() %>%
  rename("geom_ctry" = "geometry",
         "iso3" = "GID_0")

##Take the intersection of each country with the transboundary polygon, then compute its area in km2
df_int = st_intersection(ctry_bnd, df_555547988$geom) %>%
  st_as_sf() %>%
  #Compute the area in km2
  mutate(area_int_km2 = as.numeric(st_area(geom_ctry))/1e6) %>%
  group_by(area_int_km2) %>%
  slice(1) %>%
  select(c("iso3", "area_int_km2")) %>%
  st_drop_geometry()

##Define the cropped dataset
df_cropd = df_555547988 %>% 
  left_join(df_int, by = "iso3") %>%
  mutate(area_km2 = area_int_km2) %>%
  select(c(names(data_pa_nofund_nodupl))) %>%
  st_drop_geometry()

##Replace the original transboundary line by multiple lines
data_pa_ie = data_pa_nofund_nodupl %>%
  #Select all lines excepted the one to replace
  filter(is.na(wdpaid) | wdpaid != 555547988) %>%
  #Add the multiple lines 
  rbind(df_cropd)

#Finally this dataset is saved
# s3write_using(x = data_pa_ie,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_ie.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

##### FAPBM portfolio

The Fund for Protected Areas and Biodiversity in Madagascar (FAPBM in French) is the main funder of PAs in Madagascar. A dataset specific to the PAs it supports is built, knowing the name of these PAs (FAPBM website).

```{r, eval = FALSE}
#The name of PAs funded by the FAPBM, as stated on their website (https://www.fapbm.org/aires-protegees-soutenues/, consulted the 2023-09-18).
# I have removed any "-" and replace it by "".
pa_fapbm_names = data.frame(name_pa = c("Ambohitantely", "Ibity", "Corridor Marojejy-Anjanaharibe Sud-Tsaratanana","Nosy Hara","Galoko Kalobinono","Analamerana"
                   ,"Anjanaharibe Sud","Lokobe","Manongarivo", "Ambodivahibe"
                   , "Andrafiamena Andavakoera", "Ankivonjy", "Ankarana", 
                   "Montagne d’Ambre","Montagne des Français", "Loky Manambato"
                   , "Tsaratanana", "Oronjia", "Masoala", "Marojejy", "Makira"
                   , "Ivohibe", "Befotaka Midongy", "Andringitra", "Massif d’Itremo"
                   , "Agnalazaha", "Ranomafana", "Manombo", "Zombitse Voabasia"
                   , "Nosy Ve Androka", "Kalambatritra", "Cap Sainte Marie", 
                   "Beza Mahafaly", "Andranomena", "Menabe Antimena", "Mikea"
                   , "Isalo", "Tsimanampetsotse", "Complexe Mangoky Ihotry"
                   , "Kirindy Mitea", "Andohahela", "Bombetoka", "Namoroka"
                   , "Sahamalaza Îles Radama", "Complexe Tsimembo Manambolomaty"
                   , "Mandrozo", "Complexe Mahavavy Kinkony", "Bemaraha"
                   , "Beanka", "Baie de Baly", "Site bioculturel d’Antrema"
                   , "Ankarafantsika", "Corridor Ankeniheny Zahamena", "Mangerivola"
                   , "Betampona", "Andasibe Mantadia", "Analamazaotra", "Nosy Mangabe"
                   , "Mananara Nord", "Zahamena", "Marotandrano", "Maromizaha"
                   , "Analalava", "Ambatovaky")) %>%
  #Change name for some PAs that are in WDPA but with slightly different name
  #after cross-checking with polygon of WDPA on https://www.protectedplanet.net/
  #and https://www.fapbm.org/aires-protegees-soutenues/
  #Not found :
  ## Corridor Marojejy-Anjanaharibe Sud-Tsaratanana
  mutate(name_pa = case_when(name_pa == "Andasibe Mantadia" ~ "Mantadia",
                             name_pa == "Bombetoka" ~ "Bombetoka Belemboka",
                             name_pa == "Complexe Mahavavy Kinkony" ~ "Complexe Zones Humides Mahavavy Kinkony",
                             name_pa == "Complexe Mangoky Ihotry" ~ "Complexe Zones Humides Mangoky Ihotry",
                             name_pa == "Kalambatritra" ~ "Kalambatrika",
                             name_pa == "Ibity" ~ "Massif d'Ibity",
                             name_pa == "Kirindy Mitea" ~ "Kirindy Mite",
                             name_pa == "Mandrozo" ~"Zone Humide de Mandrozo",
                             name_pa == "Montagne des Français" ~"Ambohitr'Antsingy Montagne des Français",
                             name_pa == "Tsimanampetsotse" ~ "Tsimanampesotse",
                             name_pa == "Zombitse Voabasia" ~ "Zombitse Vohibasia",
                             TRUE ~ name_pa)) %>%
  mutate(name_pa_clean = janitor::make_clean_names(name_pa))

#Filter the WDPA with PA funded by FAPBM
data_pa_fapbm = data_wdpa %>%
  janitor::clean_names() %>%
  filter(iso3 == "MDG") %>%
  mutate(name_clean = make_clean_names(name), .after = "name") %>%
  filter(name_clean %in% pa_fapbm_names$name_pa_clean) %>%
  mutate(area_km2 = rep_area, .after = "rep_area") %>%
  mutate(region_afd = "DR OCEAN INDIEN", 
         name_pa = name,
         region = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.region.name"),
         sub_region = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.regionsub.name"),
         country_en = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.en"),
         country_fr = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.fr"),
         .after = "iso3") %>%
  #Add the description of IUCN from its category (French and English)
    mutate(iucn_des_fr = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national", 
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
      mutate(iucn_des_en = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Strict nature reserve",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Wilderness area",
  !is.na(wdpaid) & iucn_cat == "II" ~ "National park",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Natural monument or feature",
  !is.na(wdpaid) & iucn_cat == "IV" ~ " Habitat or species management area",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Protected landscape or seascape",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Protected area with sust. use of nat. res.",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Not categorized",
  TRUE ~ "Not referenced"), .after = iucn_cat) %>%
  mutate(year_funding_first = NA, year_funding_all = NA)


#The PA funded by FAPBM but not in the WDPA
pa_fapbm_not_found = pa_fapbm_names %>%
  filter(!(name_pa_clean %in% data_pa_fapbm$name_clean))

#Save the dataset
# s3write_using(x = data_pa_fapbm,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_FAPBM.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

##### For Madagascar

A dataset is built from the WDPA. The only modification consists in adding region and country names, plus IUCN category description.

```{r, eval = FALSE}
data_wdpa =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names()

data_pa_mdg = data_wdpa %>%
  filter(iso3 == "MDG") %>%
  mutate(name_clean = make_clean_names(name), .after = "name") %>%
  mutate(area_km2 = rep_area, .after = "rep_area") %>%
  mutate(region_afd = "DR OCEAN INDIEN", 
         name_pa = name,
         region = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.region.name"),
         sub_region = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.regionsub.name"),
         country_en = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.en"),
         country_fr = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.fr"),
         .after = "iso3") %>%
  #Add the description of IUCN from its category
    mutate(iucn_des_fr = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national", 
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
      mutate(iucn_des_en = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Strict nature reserve",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Wilderness area",
  !is.na(wdpaid) & iucn_cat == "II" ~ "National park",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Natural monument or feature",
  !is.na(wdpaid) & iucn_cat == "IV" ~ " Habitat or species management area",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Protected landscape or seascape",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Protected area with sust. use of nat. res.",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Not categorized",
  TRUE ~ "Not referenced"), .after = iucn_cat) %>%
  mutate(year_funding_first = NA, year_funding_all = NA) %>%
  #Finally compute centroid coordindates (to create maps) and dummy for FAPBM funded
  mutate(coord = st_centroid(geom),
        lon = unlist(map(coord,1)),
        lat = unlist(map(coord,2)),
         fapbm = wdpaid %in% data_pa_fapbm$wdpaid) 


#Save the dataset
# s3write_using(x = data_pa_mdg,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_MDG.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

##### For Africa

```{r, eval = FALSE}
#Import AFD funded PA
data_pa_afd =
  #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_PA_AFD_ie.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

#Import WDPA
data_wdpa =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names()

#A dataframe with region name for each iso3 code
region_iso = data_wdpa %>%
  st_drop_geometry() %>%
  clean_names() %>%
  dplyr::select(iso3) %>%
  filter(!grepl(";", iso3)) %>%
  group_by(iso3) %>%
  slice(1) %>%
  ungroup() %>%
  mutate(region_afd = "", 
       region = countrycode::countrycode(sourcevar = iso3,
                            origin = "iso3c",
                            destination = "un.region.name"),
       sub_region = countrycode::countrycode(sourcevar = iso3,
                            origin = "iso3c",
                            destination = "un.regionsub.name"),
       country_en = countrycode::countrycode(sourcevar = iso3,
                            origin = "iso3c",
                            destination = "un.name.en"),
       country_fr = countrycode::countrycode(sourcevar = iso3,
                            origin = "iso3c",
                            destination = "un.name.fr"),
       .after = "iso3")
  
africa_iso = region_iso %>% filter(region == "Africa")

data_pa_africa = data_wdpa %>%
  filter(iso3 %in% africa_iso$iso3) %>%
  filter(st_geometry_type(geom) == "MULTIPOLYGON") %>%
  st_drop_geometry() %>%
  mutate(name_clean = make_clean_names(name), 
        region_afd = "", 
       region = countrycode::countrycode(sourcevar = iso3,
                            origin = "iso3c",
                            destination = "un.region.name"),
       sub_region = countrycode::countrycode(sourcevar = iso3,
                            origin = "iso3c",
                            destination = "un.regionsub.name"),
       country_en = countrycode::countrycode(sourcevar = iso3,
                            origin = "iso3c",
                            destination = "un.name.en",
                            custom_match = c("PYF" = "French Polynesia",
                                             "ATF" = "Terres australes et antarctiques françaises",
                                             "REU" = "Reunion",
                                             "SHN" = "Saint Helena",
                                             "IOT" = "British Indian Ocean Territory",
                                               "NCL" = "New Caledonia",
                                               "MYT" = "Mayotte",
                                               "COK" = "Cook Islands",
                                               "ZZ" = "Multi-countries",
                                               "COG;CMR;CAF" = "Multi-countries")),
       country_fr = countrycode::countrycode(sourcevar = iso3,
                            origin = "iso3c",
                            destination = "un.name.fr",
                            custom_match = c("PYF" = "Polynésie Française",
                                             "ATF" = "Terres australes et antarctiques françaises",
                                             "REU" = "Réunion",
                                             "SHN" = "Saint Hélène",
                                             "IOT" = "Territoire Britannique de l'Océan Indien",
                                             
                                               "NCL" = "Nouvelle-Calédonie",
                                               "MYT" = "Mayotte",
                                               "COK" = "Iles Cook",
                                               "ZZ" = "Multi-pays",
                                               "COG;CMR;CAF" = "Multi-pays")),
       .after = "iso3") %>%
  mutate(area_km2 = rep_area, .after = "rep_area") %>%
  mutate(name_pa = name,
         .after = "iso3") %>%
  filter(region == "Africa") %>%
  #Add the description of IUCN from its category
    mutate(iucn_des_fr = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national", 
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
      mutate(iucn_des_en = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Strict nature reserve",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Wilderness area",
  !is.na(wdpaid) & iucn_cat == "II" ~ "National park",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Natural monument or feature",
  !is.na(wdpaid) & iucn_cat == "IV" ~ " Habitat or species management area",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Protected landscape or seascape",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Protected area with sust. use of nat. res.",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Not categorized",
  TRUE ~ "Not referenced"), .after = iucn_cat) %>%
  left_join(dplyr::select(data_pa_afd, c(wdpaid, year_funding_first, year_funding_all)), by = "wdpaid") %>%
  #Finally compute centroid coordindates (to create maps) and dummy for FAPBM funded
  mutate(#coord = st_centroid(geom),
        #lon = unlist(map(coord,1)),
        #lat = unlist(map(coord,2)),
        focus = wdpaid %in% data_pa_afd$wdpaid) %>%
  #Finally, we need to manually remove lines with more than one WDPA_PID
  ## Remove the marine area of WDPAID 9035 with null area
  filter(!(wdpa_pid == "9035_A")) %>%
  ## 555547861 has 3 marine PAs. The C one is chosen as the size reported by AFD (superficie_km2) matches the area reported by WDPA (https://www.protectedplanet.net/555547861)
  filter(!(wdpa_pid %in% c("555547861_A", "555547861_B"))) %>%
  # 555705345 : buffer area is also reported. Remove the buffer
  filter(!(wdpa_pid == "555705345_B")) %>%
  #555547863 : keep the WDPA_PID whose area matches the one reported by AFD employees and WDPA website (https://www.protectedplanet.net/555547863)
  filter(!(wdpa_pid == "555547863_A")) %>%
  ###761 : remove B, the buffer
  filter(!(wdpa_pid == "761_B")) %>%
  ###801 : remove the ones with null area reported
  filter(!(wdpa_pid %in% c("801_B", "801_C"))) %>%
  ###555705202 : remove B, the buffer
  filter(!(wdpa_pid == "555705202_B")) %>%
  ###555705344 : remove B, the buffer
  filter(!(wdpa_pid == "555705344_B")) %>%
  ### 555744966 : remove completely, mix of marine and non-marine
  filter(!(wdpaid == 555744966))
  

#Save the dataset
s3write_using(x = data_pa_africa,
              FUN = readr::write_delim,
              delim = ";",
              object = "data_tidy/BDD_PA_africa.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))
```

##### For TerrIndigena

Build a dataset for TerrIndigena project supported by AFD Agriculture, Rural development and Biodiversity technical division.

```{r, eval = F}

#Import datasets
##SIOP information
terr_siop =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(data.table::fread,
              object = "data_raw/TerrIndigena/TerrIndigena_siop.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  dplyr::select(c(id_projet, nom_du_projet, annee_doctroi_projet)) %>%
  group_by(id_projet) %>%
  slice(1) %>%
  ungroup() %>%
  rename("name_pa" = "nom_du_projet",
         "status_yr" = "annee_doctroi_projet")

#Polygons
##Raw
terr_poly_raw = 
    #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/TerrIndigena/TE_TerrIndigena1y2_20230208_Pg.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  #Make polygon valid to avoid errors
  st_make_valid()

##Tidy
terr_poly_tidy = terr_poly_raw %>%
  dplyr::select(c(IDentif, Pais, geom)) %>%
  mutate(IDentif = gsub(" ", "_", IDentif)) %>%
  rename("ID_raw" = "IDentif",
         "country_en" = "Pais") %>%
  #Cast multipoygons to polygon to avoid 
  st_cast("POLYGON", do_split = F) 
  
#Save the dataset
s3write_using(x = terr_poly_tidy,
              FUN = sf::st_write,
              delim = ";",
              object = "data_tidy/TerrIndigena/TE_TerrIndigena1y2_20230208_Pg_tidy.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))
```

### Datasets for confidential analysis

The first funding dataset is there to perform descriptive statistics on project funding. Thus we do not need to have one line per PA, as it is not possible to isolate the funding a given WDPAID has received. We simply save the SIOP dataset for project reported as PAs related.

```{r, eval = FALSE}
#Listing relevant variables for descriptive statistics
list_var_fund = c("id_projet", "name_pa", "id_concours",
                "wdpaid", "country_en", "country_fr", "iso3",
                "region_afd", "region", "sub_region",
                "area_km2", "rep_area", "area_afd_km2",
                "cofinanciers", "cofinanciers_siop",
                  "mt_fin_global_af_d_prevu_devise",
                  "montant_prevu_concours_euro_octroi",
                  "mt_global_projet_prevu_devise",
                  "mt_part_cofinancier_prevu_euro",
                  "libelle_produit",
                  "date_funding",
                  "year_funding")


#Defining dataset for descriptive statistics on PAs funding. Keep one row for each id_projet/id_concours/cofinanciers of SIOP
data_fund = data_tidy %>%
  select(all_of(list_var_fund)) %>%
  group_by(id_projet, id_concours, cofinanciers_siop) %>%
  slice(1)


#fwrite(data_fund, "data_tidy/BDD_AFD_fund.csv")
# s3write_using(x = data_fund,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_fund.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

Then a dataset is built with funding associated to each WDPAID. Note a project can fund several WDPAID, and that AFD funding data do not make it possible to isolate the funding of each PA defined by a WDPAID.

```{r, eval = FALSE}
data_fund_pa = data_tidy

#For PAs with WDPAIDs
data_fund_wdpa = data_fund_pa %>%
    subset(is.na(wdpaid) == FALSE) %>%
  #We need to manually remove some WDPA_PID not relevant
  ## Remove the marine area with null area of WDPAID 9035
  filter(!(wdpa_pid == "9035_A")) %>%
  ## 555547861 has 3 marine PAs. The C one is chosen as the size reported by AFD (superficie_km2) matches the area reported by WDPA (https://www.protectedplanet.net/555547861)
  filter(!(wdpa_pid %in% c("555547861_A", "555547861_B"))) %>%
  # 555705345 : buffer area is also reported. Remove the buffer
  filter(!(wdpa_pid == "555705345_B")) %>%
  #555547863 : keep the WDPA_PID whose area matches the one reported by AFD employees and WDPA website (https://www.protectedplanet.net/555547863)
  filter(!(wdpa_pid == "555547863_A")) %>%
  #Finally, keep for each WDPAID the different funding it get
  group_by(id_projet, id_concours, wdpaid, cofinanciers) %>%
  slice(1) %>%
  ungroup()

#For PAs without WDPAIDs but a name_pa : for the PA identified by name_pa, keep id_projet/id_concours/confinanciers
data_fund_name = data_fund_pa %>%
  filter(is.na(wdpaid) == TRUE & is.na(name_pa) == FALSE) %>%
  group_by(id_projet, id_concours, name_pa, cofinanciers) %>%
  slice(1) %>%
  ungroup() 

  #For PAs without WDPAIDs nor name_pa : for the PA identified by id_projet/iso3, keep id_concours/confinanciers
data_fund_na = data_fund_pa %>%
  filter(is.na(wdpaid) == TRUE & is.na(name_pa) == TRUE) %>%
  group_by(id_projet, iso3, id_concours, cofinanciers) %>%
  slice(1) %>%
  ungroup() 


data_fund_pa_nodupl = rbind(data_fund_wdpa, data_fund_name, data_fund_na)

#fwrite(data_fund, "data_tidy/BDD_PA_AFD_fund.csv")
# s3write_using(x = data_fund_pa_nodupl,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_AFD_fund_PA.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### A polygon dataset for specific use

The funding and non-funding datasets with polygon, for maps creation.

```{r, eval = FALSE}
#Loading the datasets
##WDPA data (polygons)
data_wdpa =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  select(c(wdpaid, wdpa_pid, geom)) %>%
  mutate(geom_type = sf::st_geometry_type(geom))

## Non-confidential dataset
data_pa_nofund_nodupl = 
  #fread("data_raw/BDD_PA_AFD_nofund_nodupl.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

## Confidential dataset
data_pa_fund_nodupl = 
  #fread("data_tidy/BDD_AFD_fund_PA.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_AFD_fund_PA.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

#Creating the dataset of with geospatial information (polygons)
data_pa_nofund_shp = data_pa_nofund_nodupl %>%
  left_join(data_wdpa, by = c("wdpaid", "wdpa_pid"))
data_pa_fund_shp = data_pa_fund_nodupl %>%
  left_join(data_wdpa, by = c("wdpaid", "wdpa_pid"))
data_pa_nofund_polygon_shp = data_pa_nofund_shp %>%
  filter(geom_type == "MULTIPOLYGON")


#Saving the datasets 

# st_write(pa_shp,
#          dsn = "data_tidy/BDD_pa_afd_shp_pub.gpkg",
#          delete_dsn = TRUE)
# s3write_using(x = data_pa_nofund_shp,
#               FUN = sf::st_write,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_nofund_shp.geojson",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

# st_write(pa_shp,
#          dsn = "data_tidy/BDD_pa_afd_shp_pub.gpkg",
#          delete_dsn = TRUE)
# s3write_using(x = data_pa_nofund_polygon_shp,
#               FUN = sf::st_write,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_nofund_polygon_shp.geojson",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
    
# st_write(pa_shp,
#          dsn = "data_tidy/BDD_pa_afd_shp_pub.gpkg",
#          delete_dsn = TRUE)
# s3write_using(x = data_pa_fund_shp,
#               FUN = sf::st_write,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_fund_shp.geojson",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

## Computing total areas covered by PAs in the sample

Knowing the total area covered by PAs at different level of aggregation is interesting per se. It is also necessary to compute several statistics (e.g average funding by unit of area). According to the WDPA documentation, it is likely that some reported polygons overlap. Simply summing the areas would thus lead to a biased estimate of the total area at a given level of aggregation. We follow the procedure of the WDPA (<https://www.protectedplanet.net/en/resources/calculating-protected-area-coverage>). Our case is simpler as all of the PAs we consider are given a polygon.

1.  The layer is converted to Mollweide (an equal area projection) and the area of each polygon is calculated, in km2.

2.  Intersection of polygons and the corresponding area are computed.

3.  Then the intersection can be aggregated at country, region or world level. Then it is subtracted to the sum of areas at country, region or world level. Note that intersections between PAs whose polygon is unknown won't be taken into account.

Note that the following codes are about computing total area at country/region/world level, taking potential intersections into account. It is not about generating a new shape files for the impact analysis. Indeed the overlap should be taken into account in the impact evaluation analysis codes.

### Computations of polygons' area

```{r, eval = FALSE}

#Importing shapefiles
sf_use_s2(FALSE)
pa_shp = 
  #read_sf("data_tidy/BDD_PA_AFD_shp.gpkg") %>%
  aws.s3::s3read_using(
  FUN = sf::read_sf,
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_PA_AFD_nofund_shp.gpkg",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) %>%
  #Take polygons only
  mutate(geom_type = as.character(st_geometry_type(geom))) %>%
  filter(geom_type == "MULTIPOLYGON") %>%
  #Ensure all geometries are valid
  st_make_valid() %>%
  #From multipolygon to polygon
  sf::st_cast(to="POLYGON") %>%
  #Select relevant variables
  dplyr::select(c(wdpaid, area_afd_km2, rep_area, geom, iso3, region_afd, region, sub_region, year_funding_first, year_funding_all)) 

#Spatial definition of wdpaid 555547988 overlaps CMR and CAF. Wdpaid 1245 corresponds to the CMR part. The overlap is removed and iso3 redefined so that 555547988 is CAF only. 
geom_555547988_1245 = st_difference(pa_shp[pa_shp$wdpaid == 555547988,]$geom, pa_shp[pa_shp$wdpaid == 1245,]$geom)
pa_shp[pa_shp$wdpaid == 555547988,]$geom = geom_555547988_1245
pa_shp[pa_shp$wdpaid == 555547988,]$iso3 = "CAF"

#Define a tidy version of the former dataset, with modifications on wdpaid 555547988
pa_shp_tidy = pa_shp %>%
  #Project to Mollweide to compute relevant areas in km2
  st_transform(crs = "+proj=moll +datum=WGS84") %>%
  #Compute areas in km2 from the geometry, in km2. It must be equal to gis_a by definition 
  #Then to take into account potential refinements of the geometries (as for wdpaid 55547988), a variable for relevant area is defined. It takes rep_a value except for modified geometries where area_sf_moll is taken
  mutate(area_sf_moll = as.numeric(st_area(geom)/1e6),
         area_afd_km2 = ifelse(wdpaid == 555547988, yes = area_sf_moll, no = rep_area))
```

### Computing the intersection at country, region, world level

```{r, eval = FALSE}

#Compute intersecting areas of polygons
pa_int = st_intersection(pa_shp_tidy, pa_shp_tidy) %>%
  #Remove intersection of polygons with themselves
  subset(wdpaid != wdpaid.1) %>%
  #If one of the two intersectin polygon have unknwon area, then it is not necessary to subtract the interesction area. Indeed there is no double-counting of the intersection in this case, when both polygon areas are summed.
  subset(is.na(area_afd_km2) == FALSE & is.na(area_afd_km2.1) == FALSE) %>%
  #Compute the intersecting areas (pa_shp already in Mollweide projection) in km2
  mutate(area_int = as.numeric(st_area(geom)/1e6)) %>%
  #Now duplicates need to be removed : intersection of X with Y AND intersection of Y with X are reported. We need only one.
  #An id_int to identify the intersection of a given pair
  mutate(id_int = paste0(wdpaid, "_", wdpaid.1), .before = wdpaid) %>%
  mutate(id_int_temp = paste0(wdpaid, "_", wdpaid.1), .before = wdpaid) %>%
  #create a mirror idX_idY --> idY_idX so that we identify the both member of a pair with the same id
  separate(id_int_temp, into = c("id_temp1", "id_temp2"), sep = "_") %>%
  mutate(id_int_rev = case_when(
    id_temp1 < id_temp2 ~ paste(id_temp1, id_temp2, sep = "_"),
    id_temp1 > id_temp2 ~ paste(id_temp2, id_temp1, sep = "_"),
    TRUE ~ paste(id_temp1, id_temp2, sep = "_")),
    .after = id_int) %>%
  #finally, get rid of the duplicates (have the same id_int_rev)
  group_by(id_int_rev) %>%
  slice(1) %>%
  ungroup() %>%
  #select relevant variables only
  select(wdpaid, iso3, region_afd, region, sub_region, year_funding_first, wdpaid.1, iso3.1, region_afd.1, region.1, sub_region.1, year_funding_first.1, geom, area_int)

#Computing the total area of intersections
#At country level ...
pa_int_ctry = pa_int %>%
  #Only overlapping PAs in the same country are considered
  subset(iso3 ==  iso3.1) %>%
  group_by(iso3) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()

#At region level
#AFD regions : not performed as some PAs have multiple DR and only one kept
# pa_int_dr = pa_int %>%
#   #Only overlapping PAs in the same DR are considered
#   subset(region_afd == region_afd.1) %>%
#   group_by(region_afd) %>%
#   summarize(tot_area_int = sum(area_int)) %>%
#   st_drop_geometry()

#UN regions
pa_int_region = pa_int %>%
  #Only overlapping PAs in the same DR are considered
  subset(region == region.1) %>%
  group_by(region) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()
#UN sub-regions
pa_int_subregion = pa_int %>%
  #Only overlapping PAs in the same DR are considered
  subset(sub_region == sub_region.1) %>%
  group_by(sub_region) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()

##At world level : all overlap are considered
pa_int_wld = sum(pa_int$area_int) 

#Compute the total intersection for each year
pa_int_yr = pa_int %>%
  #Define intersection year : the date ann_c of the later PA in the pair
  rowwise() %>%
  mutate(annee_int = max(year_funding_first, year_funding_first.1)) %>% 
  group_by(annee_int) %>%
  summarize(tot_int_km2 = sum(area_int)) %>%
  st_drop_geometry()

# fwrite(pa_int_yr,
#        "data_tidy/area/pa_int_yr.csv")
s3write_using(x = pa_int_yr,
              FUN = data.table::fwrite,
              object = "data_tidy/area/pa_int_yr.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))
```

### Computing total areas without intersection

```{r, eval = FALSE}

data_pa_afd = 
  #fread("data_raw/BDD_PA_AFD_nofund_nodupl.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

#At country level ...
pa_area_ctry = data_pa_afd %>%
  #Compute total area at country level
  group_by(iso3) %>%
  summarize(area_tot_km2 = sum(area_afd_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  #Add information on intersection area in each country. Modify the variable so that NA value -> 0
  left_join(pa_int_ctry, by = "iso3") %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~ 0, TRUE ~ tot_area_int)) %>%
  #Compute the total area at country level without intersection
  mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) 

#fwrite(pa_area_ctry, "data_tidy/area/pa_area_ctry.csv")
# s3write_using(x = pa_area_ctry,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_ctry.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At AFD region level ...
# pa_area_dr = data_pa_afd %>%
#   #Compute total area at dr level
#   group_by(region_afd) %>%
#   summarize(area_tot_km2 = sum(area_afd_km2, na.rm = TRUE)) %>% 
#   ungroup() %>%
#   #Add information on intersection area in each DR. Modify the variable so that NA value -> 0
#   left_join(pa_int_dr, by = "region_afd") %>%
#   mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~0, TRUE ~tot_area_int)) %>%
#   #Compute the total area at country level without intersection
#     mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) %>%
#   st_drop_geometry()
# 
# #fwrite(pa_area_dr, "data_tidy/area/pa_area_dr.csv")
# s3write_using(x = pa_area_dr,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_dr.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At UN region level
pa_area_region = data_pa_afd %>%
  #Compute total area at dr level
  group_by(region) %>%
  summarize(area_tot_km2 = sum(area_afd_km2, na.rm = TRUE)) %>% 
  ungroup() %>%
  #Add information on intersection area in each DR. Modify the variable so that NA value -> 0
  left_join(pa_int_region, by = "region") %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~0, TRUE ~tot_area_int)) %>%
  #Compute the total area at country level without intersection
    mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) %>%
  st_drop_geometry()

#fwrite(pa_area_dr, "data_tidy/area/pa_area_dr.csv")
# s3write_using(x = pa_area_region,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_region.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At UN sub-region level
pa_area_subregion = data_pa_afd %>%
  #Compute total area at dr level
  group_by(sub_region) %>%
  summarize(area_tot_km2 = sum(area_afd_km2, na.rm = TRUE)) %>% 
  ungroup() %>%
  #Add information on intersection area in each DR. Modify the variable so that NA value -> 0
  left_join(pa_int_subregion, by = "sub_region") %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~0, TRUE ~tot_area_int)) %>%
  #Compute the total area at country level without intersection
    mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) %>%
  st_drop_geometry()

#fwrite(pa_area_dr, "data_tidy/area/pa_area_dr.csv")
# s3write_using(x = pa_area_subregion,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_subregion.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At world level
pa_area_wld = sum(data_pa_afd$area_afd_km2, na.rm = TRUE) - pa_int_wld %>%
  as.data.frame() %>%
  rename("area_tot_noint_km2" = ".")
#fwrite(pa_area_wld, "data_tidy/area/pa_area_wld.csv")
# s3write_using(x = pa_area_wld,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_wld.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```
